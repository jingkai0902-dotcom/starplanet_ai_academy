{
  "title": "AI知识总表",
  "source": "C:\\Users\\Frank.J\\starplanet_ai_academy\\知识库\\02_知识点数据库\\AI知识库\\AI知识总表.md",
  "sections": [
    {
      "title": "快速导航",
      "content": "| 技术类别 | 包含内容 | 详情链接 |\n|----------|---------|---------|\n| 计算机视觉 | OpenCV、图像处理 | [计算机视觉.md](计算机视觉.md) |\n| 人脸识别 | FaceMesh、特征匹配 | [人脸识别.md](人脸识别.md) |\n| 手势识别 | MediaPipe Hands | [手势识别.md](手势识别.md) |\n\n---"
    },
    {
      "title": "AI技术总览",
      "content": "### 按课程分布\n\n| 课程编号 | AI技术 | 具体应用 |\n|----------|--------|---------|\n| PYAI 1-4-6 | OpenCV基础 | 摄像头采集、人脸捕捉 |\n| PYAI 1-4-7 | 特征匹配 | 人脸比对算法 |\n| PYAI 1-4-8 | AI+硬件 | 刷脸开门系统 |\n| PYAI 2-3-1 | MediaPipe FaceMesh | 眼睛关键点检测 |\n| PYAI 2-3-2 | 眨眼检测 | 阈值判定、状态机 |\n| PYAI 2-3-3 | 眼控开关 | AI+GPIO控制 |\n| PYAI 2-3-5 | 表情识别 | 微笑/张嘴检测 |\n| PYAI 2-3-6 | 表情强度 | 表情仪表盘 |\n| PYAI 2-3-7 | MediaPipe Hands | 手部21关键点 |\n| PYAI 2-3-8 | 手势控制 | 手势映射游戏 |\n| PYAI 2-3-9 | 指尖追踪 | 空中绘画板 |\n| PYAI 2-3-10/11 | 随机算法 | 猜拳机器人 |\n\n---"
    },
    {
      "title": "一、计算机视觉基础",
      "content": "### 1.1 OpenCV库\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 1-4-6 | 智能门禁(1) | 摄像头采集 |\n| PYAI 1-4-7 | 智能门禁(2) | 图像处理 |\n\n#### 核心代码\n```python\nimport cv2\n\n# 打开摄像头\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # 读取一帧\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # 显示画面\n    cv2.imshow('Camera', frame)\n\n    # 按q退出\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# 释放资源（重要！）\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 1.2 图像处理\n\n#### 灰度转换\n```python\n# 彩色图转灰度图\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n```\n\n#### 图像绘制\n```python\n# 画线\ncv2.line(frame, (0, 0), (100, 100), (255, 0, 0), 2)\n\n# 画圆\ncv2.circle(frame, (50, 50), 20, (0, 255, 0), -1)\n\n# 画矩形\ncv2.rectangle(frame, (10, 10), (100, 100), (0, 0, 255), 2)\n\n# 写文字\ncv2.putText(frame, 'Hello', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n```\n\n---"
    },
    {
      "title": "二、人脸识别",
      "content": "### 2.1 人脸捕捉与比对\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 1-4-6 | 人脸捕捉 | 采集人脸图像 |\n| PYAI 1-4-7 | 人脸比对 | 模板匹配算法 |\n| PYAI 1-4-8 | 刷脸开门 | AI+舵机控制 |\n\n#### 模板匹配\n```python\nimport cv2\n\n# 读取模板（已注册的人脸）\ntemplate = cv2.imread('registered_face.jpg', 0)\n\n# 读取当前帧并转灰度\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n# 模板匹配\nresult = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)\n\n# 获取最大匹配值\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\n# 判断是否匹配\nif max_val > 0.8:  # 相似度阈值\n    print(\"人脸匹配成功！\")\n    # 控制舵机开门\n    servo.write_angle(90)\n```\n\n### 2.2 MediaPipe FaceMesh\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-1 | FaceMesh基础 | 468个面部关键点 |\n| PYAI 2-3-2 | 眨眼检测 | 眼睛关键点距离 |\n\n#### 核心代码\n```python\nimport cv2\nimport mediapipe as mp\n\n# 初始化FaceMesh\nmp_face_mesh = mp.solutions.face_mesh\nface_mesh = mp_face_mesh.FaceMesh(\n    max_num_faces=1,\n    min_detection_confidence=0.5\n)\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # 转换颜色空间\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # 检测人脸\n    results = face_mesh.process(rgb_frame)\n\n    if results.multi_face_landmarks:\n        for face_landmarks in results.multi_face_landmarks:\n            # 获取关键点\n            for idx, landmark in enumerate(face_landmarks.landmark):\n                h, w, c = frame.shape\n                x = int(landmark.x * w)\n                y = int(landmark.y * h)\n                # 绘制关键点\n                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n\n    cv2.imshow('FaceMesh', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 2.3 眨眼检测\n\n#### 关键点索引\n```\n左眼上眼皮: 159\n左眼下眼皮: 145\n右眼上眼皮: 386\n右眼下眼皮: 374\n```\n\n#### 眨眼检测代码\n```python\ndef get_eye_distance(landmarks, upper_idx, lower_idx):\n    \"\"\"计算眼睛开合距离\"\"\"\n    upper = landmarks[upper_idx]\n    lower = landmarks[lower_idx]\n    return abs(upper.y - lower.y)\n\n# 检测眨眼\nleft_eye_dist = get_eye_distance(landmarks, 159, 145)\nright_eye_dist = get_eye_distance(landmarks, 386, 374)\navg_eye_dist = (left_eye_dist + right_eye_dist) / 2\n\n# 阈值判断\nBLINK_THRESHOLD = 0.02\nif avg_eye_dist < BLINK_THRESHOLD:\n    print(\"检测到眨眼！\")\n```\n\n---"
    },
    {
      "title": "三、表情识别",
      "content": "### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-5 | 表情音乐播放器 | 微笑/张嘴检测 |\n| PYAI 2-3-6 | 表情仪表盘 | 表情强度计算 |\n\n### 3.1 微笑检测\n\n#### 关键点索引\n```\n嘴角左: 61\n嘴角右: 291\n嘴巴中心: 13\n```\n\n#### 微笑检测代码\n```python\ndef detect_smile(landmarks):\n    \"\"\"检测微笑\"\"\"\n    left_corner = landmarks[61]\n    right_corner = landmarks[291]\n    mouth_center = landmarks[13]\n\n    # 嘴角上扬判断\n    left_lift = mouth_center.y - left_corner.y\n    right_lift = mouth_center.y - right_corner.y\n\n    if left_lift > 0.01 and right_lift > 0.01:\n        return True, (left_lift + right_lift) / 2\n    return False, 0\n```\n\n### 3.2 张嘴检测\n\n#### 关键点索引\n```\n上嘴唇: 13\n下嘴唇: 14\n```\n\n#### 张嘴检测代码\n```python\ndef detect_mouth_open(landmarks):\n    \"\"\"检测张嘴\"\"\"\n    upper_lip = landmarks[13]\n    lower_lip = landmarks[14]\n\n    mouth_open = abs(upper_lip.y - lower_lip.y)\n\n    MOUTH_THRESHOLD = 0.05\n    return mouth_open > MOUTH_THRESHOLD\n```\n\n---"
    },
    {
      "title": "四、手势识别",
      "content": "### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-7 | MediaPipe Hands | 21个手部关键点 |\n| PYAI 2-3-8 | 手势控制 | 手势映射 |\n| PYAI 2-3-9 | 指尖追踪 | 空中绘画 |\n\n### 4.1 手部关键点\n\n```\n手部21个关键点索引：\n0  - 手腕\n1-4   - 拇指（1=根部, 4=指尖）\n5-8   - 食指（5=根部, 8=指尖）\n9-12  - 中指（9=根部, 12=指尖）\n13-16 - 无名指（13=根部, 16=指尖）\n17-20 - 小拇指（17=根部, 20=指尖）\n```\n\n### 4.2 手势识别代码\n\n```python\nimport cv2\nimport mediapipe as mp\n\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(\n    max_num_hands=1,\n    min_detection_confidence=0.7\n)\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    results = hands.process(rgb_frame)\n\n    if results.multi_hand_landmarks:\n        for hand_landmarks in results.multi_hand_landmarks:\n            # 获取关键点\n            landmarks = hand_landmarks.landmark\n\n            # 判断手指是否伸直\n            fingers_up = []\n\n            # 拇指（比较x坐标）\n            if landmarks[4].x < landmarks[3].x:\n                fingers_up.append(1)\n            else:\n                fingers_up.append(0)\n\n            # 其他四指（比较y坐标，指尖低于第二关节）\n            for tip_idx in [8, 12, 16, 20]:\n                if landmarks[tip_idx].y < landmarks[tip_idx - 2].y:\n                    fingers_up.append(1)\n                else:\n                    fingers_up.append(0)\n\n            print(f\"手指状态: {fingers_up}\")\n\n    cv2.imshow('Hands', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 4.3 手势映射\n\n```python\n# 手势到指令的映射\nGESTURE_MAP = {\n    (0, 1, 0, 0, 0): 'UP',      # 只伸食指 = 上\n    (0, 1, 1, 0, 0): 'DOWN',    # 食指+中指 = 下\n    (1, 1, 1, 1, 1): 'STOP',    # 全部伸开 = 停止\n    (0, 0, 0, 0, 0): 'FIST',    # 握拳\n}\n\ndef get_gesture(fingers_up):\n    return GESTURE_MAP.get(tuple(fingers_up), 'UNKNOWN')\n```\n\n### 4.4 指尖追踪绘画\n\n```python\n# 获取食指指尖坐标\nindex_tip = landmarks[8]\nh, w, c = frame.shape\nx = int(index_tip.x * w)\ny = int(index_tip.y * h)\n\n# 绘制轨迹\nif prev_x is not None:\n    cv2.line(canvas, (prev_x, prev_y), (x, y), draw_color, 5)\n\nprev_x, prev_y = x, y\n```\n\n---"
    },
    {
      "title": "五、AIoT系统集成",
      "content": "### 架构模式\n\n```\n┌─────────────────────────────────────┐\n│           应用层（执行）              │\n│   LED、舵机、蜂鸣器、屏幕显示         │\n└─────────────────────────────────────┘\n                   ↑\n┌─────────────────────────────────────┐\n│           处理层（AI决策）            │\n│   MediaPipe、OpenCV、状态机          │\n└─────────────────────────────────────┘\n                   ↑\n┌─────────────────────────────────────┐\n│           感知层（输入）              │\n│   摄像头、传感器                      │\n└─────────────────────────────────────┘\n```\n\n### 典型项目\n\n| 项目 | 感知 | AI处理 | 执行 |\n|------|------|--------|------|\n| 眼控开关 | 摄像头 | 眨眼检测 | LED |\n| 刷脸门禁 | 摄像头 | 人脸匹配 | 舵机 |\n| 手势控制 | 摄像头 | 手势识别 | 游戏/硬件 |\n| 表情音乐 | 摄像头 | 表情识别 | 音频播放 |\n\n---"
    },
    {
      "title": "六、常见错误与禁忌",
      "content": "| 错误 | 后果 | 正确做法 |\n|------|------|---------|\n| ❌ 忘记释放摄像头 | 下次无法使用 | 程序结束前调用`cap.release()` |\n| ❌ BGR/RGB颜色空间混淆 | 颜色显示错误 | OpenCV用BGR，MediaPipe用RGB |\n| ❌ 阈值设置不当 | 识别不准确 | 根据实际环境调整阈值 |\n| ❌ 未处理检测失败 | 程序崩溃 | 检查`results`是否为None |\n\n---\n\n**维护者**：���识库管理员\n**数据来源**：萃取报告/PythonAI/\n**整合原则**：基于现有萃取报告，不压缩删减"
    }
  ],
  "full_content": "# AI知识总表\n\n> **用途**：跨课程AI知识汇总，快速查找AI技术在各课程的应用\n> **更新日期**：2026-02-10\n> **数据来源**：萃取报告/PythonAI/\n> **整合原则**：基于现有萃取报告，不压缩删减\n\n---\n\n## 快速导航\n\n| 技术类别 | 包含内容 | 详情链接 |\n|----------|---------|---------|\n| 计算机视觉 | OpenCV、图像处理 | [计算机视觉.md](计算机视觉.md) |\n| 人脸识别 | FaceMesh、特征匹配 | [人脸识别.md](人脸识别.md) |\n| 手势识别 | MediaPipe Hands | [手势识别.md](手势识别.md) |\n\n---\n\n## AI技术总览\n\n### 按课程分布\n\n| 课程编号 | AI技术 | 具体应用 |\n|----------|--------|---------|\n| PYAI 1-4-6 | OpenCV基础 | 摄像头采集、人脸捕捉 |\n| PYAI 1-4-7 | 特征匹配 | 人脸比对算法 |\n| PYAI 1-4-8 | AI+硬件 | 刷脸开门系统 |\n| PYAI 2-3-1 | MediaPipe FaceMesh | 眼睛关键点检测 |\n| PYAI 2-3-2 | 眨眼检测 | 阈值判定、状态机 |\n| PYAI 2-3-3 | 眼控开关 | AI+GPIO控制 |\n| PYAI 2-3-5 | 表情识别 | 微笑/张嘴检测 |\n| PYAI 2-3-6 | 表情强度 | 表情仪表盘 |\n| PYAI 2-3-7 | MediaPipe Hands | 手部21关键点 |\n| PYAI 2-3-8 | 手势控制 | 手势映射游戏 |\n| PYAI 2-3-9 | 指尖追踪 | 空中绘画板 |\n| PYAI 2-3-10/11 | 随机算法 | 猜拳机器人 |\n\n---\n\n## 一、计算机视觉基础\n\n### 1.1 OpenCV库\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 1-4-6 | 智能门禁(1) | 摄像头采集 |\n| PYAI 1-4-7 | 智能门禁(2) | 图像处理 |\n\n#### 核心代码\n```python\nimport cv2\n\n# 打开摄像头\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # 读取一帧\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # 显示画面\n    cv2.imshow('Camera', frame)\n\n    # 按q退出\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# 释放资源（重要！）\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 1.2 图像处理\n\n#### 灰度转换\n```python\n# 彩色图转灰度图\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n```\n\n#### 图像绘制\n```python\n# 画线\ncv2.line(frame, (0, 0), (100, 100), (255, 0, 0), 2)\n\n# 画圆\ncv2.circle(frame, (50, 50), 20, (0, 255, 0), -1)\n\n# 画矩形\ncv2.rectangle(frame, (10, 10), (100, 100), (0, 0, 255), 2)\n\n# 写文字\ncv2.putText(frame, 'Hello', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n```\n\n---\n\n## 二、人脸识别\n\n### 2.1 人脸捕捉与比对\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 1-4-6 | 人脸捕捉 | 采集人脸图像 |\n| PYAI 1-4-7 | 人脸比对 | 模板匹配算法 |\n| PYAI 1-4-8 | 刷脸开门 | AI+舵机控制 |\n\n#### 模板匹配\n```python\nimport cv2\n\n# 读取模板（已注册的人脸）\ntemplate = cv2.imread('registered_face.jpg', 0)\n\n# 读取当前帧并转灰度\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n# 模板匹配\nresult = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)\n\n# 获取最大匹配值\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\n# 判断是否匹配\nif max_val > 0.8:  # 相似度阈值\n    print(\"人脸匹配成功！\")\n    # 控制舵机开门\n    servo.write_angle(90)\n```\n\n### 2.2 MediaPipe FaceMesh\n\n#### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-1 | FaceMesh基础 | 468个面部关键点 |\n| PYAI 2-3-2 | 眨眼检测 | 眼睛关键点距离 |\n\n#### 核心代码\n```python\nimport cv2\nimport mediapipe as mp\n\n# 初始化FaceMesh\nmp_face_mesh = mp.solutions.face_mesh\nface_mesh = mp_face_mesh.FaceMesh(\n    max_num_faces=1,\n    min_detection_confidence=0.5\n)\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # 转换颜色空间\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # 检测人脸\n    results = face_mesh.process(rgb_frame)\n\n    if results.multi_face_landmarks:\n        for face_landmarks in results.multi_face_landmarks:\n            # 获取关键点\n            for idx, landmark in enumerate(face_landmarks.landmark):\n                h, w, c = frame.shape\n                x = int(landmark.x * w)\n                y = int(landmark.y * h)\n                # 绘制关键点\n                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n\n    cv2.imshow('FaceMesh', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 2.3 眨眼检测\n\n#### 关键点索引\n```\n左眼上眼皮: 159\n左眼下眼皮: 145\n右眼上眼皮: 386\n右眼下眼皮: 374\n```\n\n#### 眨眼检测代码\n```python\ndef get_eye_distance(landmarks, upper_idx, lower_idx):\n    \"\"\"计算眼睛开合距离\"\"\"\n    upper = landmarks[upper_idx]\n    lower = landmarks[lower_idx]\n    return abs(upper.y - lower.y)\n\n# 检测眨眼\nleft_eye_dist = get_eye_distance(landmarks, 159, 145)\nright_eye_dist = get_eye_distance(landmarks, 386, 374)\navg_eye_dist = (left_eye_dist + right_eye_dist) / 2\n\n# 阈值判断\nBLINK_THRESHOLD = 0.02\nif avg_eye_dist < BLINK_THRESHOLD:\n    print(\"检测到眨眼！\")\n```\n\n---\n\n## 三、表情识别\n\n### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-5 | 表情音乐播放器 | 微笑/张嘴检测 |\n| PYAI 2-3-6 | 表情仪表盘 | 表情强度计算 |\n\n### 3.1 微笑检测\n\n#### 关键点索引\n```\n嘴角左: 61\n嘴角右: 291\n嘴巴中心: 13\n```\n\n#### 微笑检测代码\n```python\ndef detect_smile(landmarks):\n    \"\"\"检测微笑\"\"\"\n    left_corner = landmarks[61]\n    right_corner = landmarks[291]\n    mouth_center = landmarks[13]\n\n    # 嘴角上扬判断\n    left_lift = mouth_center.y - left_corner.y\n    right_lift = mouth_center.y - right_corner.y\n\n    if left_lift > 0.01 and right_lift > 0.01:\n        return True, (left_lift + right_lift) / 2\n    return False, 0\n```\n\n### 3.2 张嘴检测\n\n#### 关键点索引\n```\n上嘴唇: 13\n下嘴唇: 14\n```\n\n#### 张嘴检测代码\n```python\ndef detect_mouth_open(landmarks):\n    \"\"\"检测张嘴\"\"\"\n    upper_lip = landmarks[13]\n    lower_lip = landmarks[14]\n\n    mouth_open = abs(upper_lip.y - lower_lip.y)\n\n    MOUTH_THRESHOLD = 0.05\n    return mouth_open > MOUTH_THRESHOLD\n```\n\n---\n\n## 四、手势识别\n\n### 跨课程出现\n\n| 课程编号 | 课程名称 | 具体内容 |\n|----------|---------|---------|\n| PYAI 2-3-7 | MediaPipe Hands | 21个手部关键点 |\n| PYAI 2-3-8 | 手势控制 | 手势映射 |\n| PYAI 2-3-9 | 指尖追踪 | 空中绘画 |\n\n### 4.1 手部关键点\n\n```\n手部21个关键点索引：\n0  - 手腕\n1-4   - 拇指（1=根部, 4=指尖）\n5-8   - 食指（5=根部, 8=指尖）\n9-12  - 中指（9=根部, 12=指尖）\n13-16 - 无名指（13=根部, 16=指尖）\n17-20 - 小拇指（17=根部, 20=指尖）\n```\n\n### 4.2 手势识别代码\n\n```python\nimport cv2\nimport mediapipe as mp\n\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(\n    max_num_hands=1,\n    min_detection_confidence=0.7\n)\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    results = hands.process(rgb_frame)\n\n    if results.multi_hand_landmarks:\n        for hand_landmarks in results.multi_hand_landmarks:\n            # 获取关键点\n            landmarks = hand_landmarks.landmark\n\n            # 判断手指是否伸直\n            fingers_up = []\n\n            # 拇指（比较x坐标）\n            if landmarks[4].x < landmarks[3].x:\n                fingers_up.append(1)\n            else:\n                fingers_up.append(0)\n\n            # 其他四指（比较y坐标，指尖低于第二关节）\n            for tip_idx in [8, 12, 16, 20]:\n                if landmarks[tip_idx].y < landmarks[tip_idx - 2].y:\n                    fingers_up.append(1)\n                else:\n                    fingers_up.append(0)\n\n            print(f\"手指状态: {fingers_up}\")\n\n    cv2.imshow('Hands', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n### 4.3 手势映射\n\n```python\n# 手势到指令的映射\nGESTURE_MAP = {\n    (0, 1, 0, 0, 0): 'UP',      # 只伸食指 = 上\n    (0, 1, 1, 0, 0): 'DOWN',    # 食指+中指 = 下\n    (1, 1, 1, 1, 1): 'STOP',    # 全部伸开 = 停止\n    (0, 0, 0, 0, 0): 'FIST',    # 握拳\n}\n\ndef get_gesture(fingers_up):\n    return GESTURE_MAP.get(tuple(fingers_up), 'UNKNOWN')\n```\n\n### 4.4 指尖追踪绘画\n\n```python\n# 获取食指指尖坐标\nindex_tip = landmarks[8]\nh, w, c = frame.shape\nx = int(index_tip.x * w)\ny = int(index_tip.y * h)\n\n# 绘制轨迹\nif prev_x is not None:\n    cv2.line(canvas, (prev_x, prev_y), (x, y), draw_color, 5)\n\nprev_x, prev_y = x, y\n```\n\n---\n\n## 五、AIoT系统集成\n\n### 架构模式\n\n```\n┌─────────────────────────────────────┐\n│           应用层（执行）              │\n│   LED、舵机、蜂鸣器、屏幕显示         │\n└─────────────────────────────────────┘\n                   ↑\n┌─────────────────────────────────────┐\n│           处理层（AI决策）            │\n│   MediaPipe、OpenCV、状态机          │\n└─────────────────────────────────────┘\n                   ↑\n┌─────────────────────────────────────┐\n│           感知层（输入）              │\n│   摄像头、传感器                      │\n└─────────────────────────────────────┘\n```\n\n### 典型项目\n\n| 项目 | 感知 | AI处理 | 执行 |\n|------|------|--------|------|\n| 眼控开关 | 摄像头 | 眨眼检测 | LED |\n| 刷脸门禁 | 摄像头 | 人脸匹配 | 舵机 |\n| 手势控制 | 摄像头 | 手势识别 | 游戏/硬件 |\n| 表情音乐 | 摄像头 | 表情识别 | 音频播放 |\n\n---\n\n## 六、常见错误与禁忌\n\n| 错误 | 后果 | 正确做法 |\n|------|------|---------|\n| ❌ 忘记释放摄像头 | 下次无法使用 | 程序结束前调用`cap.release()` |\n| ❌ BGR/RGB颜色空间混淆 | 颜色显示错误 | OpenCV用BGR，MediaPipe用RGB |\n| ❌ 阈值设置不当 | 识别不准确 | 根据实际环境调整阈值 |\n| ❌ 未处理检测失败 | 程序崩溃 | 检查`results`是否为None |\n\n---\n\n**维护者**：���识库管理员\n**数据来源**：萃取报告/PythonAI/\n**整合原则**：基于现有萃取报告，不压缩删减\n"
}