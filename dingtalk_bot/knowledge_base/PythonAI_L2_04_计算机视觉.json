{
  "title": "PythonAI萃取：L2-4 计算机视觉CV",
  "source": "C:\\Users\\Frank.J\\starplanet_ai_academy\\知识库\\萃取报告\\PythonAI\\L2_04_计算机视觉.md",
  "sections": [
    {
      "title": "单元概览",
      "content": "| 项目 | 内容 |\n|------|------|\n| **单元编号** | PYAI 2-4 |\n| **单元名称** | 计算机视觉 (Computer Vision) |\n| **适用年龄** | 四年级及以上（10-12岁） |\n| **课时数** | 12节 × 90分钟 |\n| **核心目标** | 深入图像处理底层原理，从像素操作到卷积运算，再到高级AI模型应用 |\n| **核心库** | OpenCV (cv2), NumPy, MediaPipe |\n\n**底层逻辑**\n深入图像处理底层原理，实现特效与增强现实(AR)应用。理解图像的数字本质，掌握AI视觉模型的应用。\n\n**单元教学策略**\n- 视频基础（01）：视频本质、帧率、循环播放\n- 像素操作（03-04）：NumPy数组、亮度调整、ROI\n- 滤波处理（05-06）：卷积核、降噪、二值化\n- AI模型（08-12）：人像分割、AR增强现实\n\n`#执行层` `#测评项`\n[UID: PYAI-24-001]\n[关联: PYAI-14-001 PythonAI智能硬件（前置基础）]\n[关联: PYAI-23-001 PythonAI交互式AI（并行学习）]\n\n---"
    },
    {
      "title": "课程列表",
      "content": "| 课次 | 课程名称 | 核心知识点 | 项目内容 | 认知负荷 |\n|------|----------|------------|----------|----------|\n| 2-4-1 | 视频基础 | cv2.VideoCapture、帧率控制、循环播放 | 视频播放器 | 中 |\n| 2-4-3 | 图像编辑1 | NumPy数组、像素操作、亮度调整 | 图片变暗/反色 | 中-高 |\n| 2-4-4 | 图像编辑2 | ROI区域替换、cv2.resize、os.listdir | 局部马赛克 | 高 |\n| 2-4-5 | 滤波降噪 | 均值/高斯/中值滤波、卷积核 | 图片降噪器 | 高 |\n| 2-4-6 | 文件扫描 | 二值化cv2.threshold、去阴影cv2.divide | 文档扫描仪 | 高 |\n| 2-4-8/9 | 人像分割 | Selfie Segmentation、Mask掩膜、numpy.where | 视频会议虚拟背景 | 高 |\n| 2-4-10/11 | 虚拟墨镜 | FaceMesh 468点、Alpha通道、几何计算 | AR试戴 | 高 |\n| 2-4-12 | 动物伙伴 | Pose模型、GIF处理、位置跟随 | 肩膀上的宠物 | 高 |\n\n---"
    },
    {
      "title": "通用教学流程（90分钟）",
      "content": "| 环节 | 时间 | 内容 | 认知负荷 | IFC标签 |\n|------|------|------|----------|---------|\n| 课堂问候 | 2分钟 | 自我介绍、学习目标 | `#低负荷-热身` | `#IFC-预防` |\n| 课程回顾 | 5分钟 | 复习上节课代码和概念 | `#低负荷-热身` | `#IFC-预防` |\n| 知识讲解 | 20分钟 | 新概念/算法讲解 | `#中负荷-操练` | `#IFC-即时` |\n| 代码实践 | 35分钟 | 编写代码、调试运行 | `#高负荷-产出` | `#IFC-即时` |\n| 调节休息 | 3分钟 | 站起来活动、眼保健操 | `#调节-放松` | - |\n| 项目拓展 | 15分钟 | 自由创作/挑战任务 | `#高负荷-产出` | `#IFC-即时` |\n| 成果展示 | 10分钟 | 分享代码、讲解思路 | `#低负荷-热身` | `#IFC-复盘` |\n\n`#执行层` `#测评项`\n[UID: PYAI-24-FLOW-001]\n\n---"
    },
    {
      "title": "详细课程萃取",
      "content": "### 2-4-1 视频基础\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-1 |\n| **课程名称** | 视频基础 - 视频播放器 |\n| **认知负荷** | 中 |\n| **核心技能** | cv2.VideoCapture、帧率控制、循环播放 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来揭开视频的秘密！大家知道视频是什么吗？其实视频就是**很多张图片快速播放**！\n>\n> 就像翻书动画一样，每秒播放24张以上的图片，人眼就会觉得是连续的动作。这个'每秒多少张'就叫做**帧率(FPS)**。\n>\n> ```python\n> import cv2\n>\n> # 打开视频文件\n> cap = cv2.VideoCapture('video.mp4')\n>\n> # 获取视频信息\n> fps = cap.get(cv2.CAP_PROP_FPS)  # 帧率\n> width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # 宽度\n> height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # 高度\n> print(f'帧率: {fps}, 尺寸: {width}x{height}')\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解帧率 | 用翻书动画演示 | 准备一本翻页动画书 |\n| 想用摄像头 | 改用设备编号 | `cv2.VideoCapture(0)` 打开默认摄像头 |\n| 视频打不开 | 检查路径 | 确认文件路径正确，使用绝对路径 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来写一个视频播放器！关键是用**while循环**不断读取每一帧：\n>\n> ```python\n> while True:\n>     ret, frame = cap.read()  # 读取一帧\n>\n>     if not ret:  # 视频结束\n>         cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # 回到开头，循环播放\n>         continue\n>\n>     cv2.imshow('Video Player', frame)\n>\n>     # 按Q键退出\n>     if cv2.waitKey(30) & 0xFF == ord('q'):\n>         break\n>\n> cap.release()  # 释放资源\n> cv2.destroyAllWindows()\n> ```\n>\n> **重点**：`cv2.waitKey(30)` 控制播放速度，30毫秒约等于33帧/秒。\"\n\n**核心代码模式**\n\n```python\n# 视频播放标准模板\ncap = cv2.VideoCapture('video.mp4')\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break  # 或循环播放\n    cv2.imshow('Window', frame)\n    if cv2.waitKey(30) & 0xFF == ord('q'):\n        break\ncap.release()\ncv2.destroyAllWindows()\n```\n\n**禁忌提醒**\n- 忘记`cv2.waitKey()`——窗口会卡死无响应\n- 忘记`cap.release()`——下次无法打开摄像头\n- waitKey参数为0——会暂停等待按键\n\n---\n\n**核心知识点**\n- 视频本质：连续图片帧的快速播放\n- 帧率(FPS)：每秒播放的帧数，通常24-60fps\n- VideoCapture：OpenCV读取视频/摄像头的核心类\n- waitKey：控制播放速度和键盘响应\n\n`#执行层` `#测评项`\n[UID: PYAI-24-01-001]\n[关联: PYAI-24-03-001 图像编辑（后续课程）]\n\n---\n\n### 2-4-3 图像编辑1（典型案例）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-3 |\n| **课程名称** | 图像编辑1 - 像素操作 |\n| **认知负荷** | 中-高 |\n| **核心技能** | NumPy数组、像素操作、亮度调整 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们要揭开图像的秘密！大家知道吗，电脑看到的图片其实是一堆数字。每个像素都是一个数字，范围是0-255。0是黑色，255是白色。\"\n>\n> \"在Python里，图片被读成一个NumPy数组：\n> ```python\n> import cv2\n> img = cv2.imread('photo.jpg')\n> print(img.shape)  # (高度, 宽度, 通道数)\n> ```\n>\n> 彩色图片有3个通道：蓝(B)、绿(G)、红(R)。注意，OpenCV的顺序是BGR，不是RGB！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解数组 | 用Excel类比 | \"图片就像一个巨大的Excel表格，每格是一个数字\" |\n| 混淆BGR和RGB | 强调顺序 | \"OpenCV用BGR，就像'倒着读'一样\" |\n| 想深入了解 | 展示单通道 | 分别显示B、G、R三个通道的灰度图 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来修改图片亮度。原理很简单：把所有像素值减小，图片就变暗了！\n>\n> ```python\n> dark_img = img - 50  # 每个像素减50，变暗\n> bright_img = img + 50  # 每个像素加50，变亮\n> ```\n>\n> 还可以做反色效果：\n> ```python\n> inverted = 255 - img  # 黑变白，白变黑\n> ```\"\n\n**禁忌提醒**\n❌ 像素值超出0-255范围——会导致颜色异常\n❌ 忘记转换数据类型——可能出现溢出错误\n\n---\n\n**步骤3：成果展示（10分钟）** `#低负荷-热身` `#IFC-复盘`\n\n**教师话术**\n> \"谁来展示一下你的作品？告诉大家你用了什么方法修改图片？\"\n\n---\n\n**核心知识点**\n- NumPy数组：图像的矩阵本质\n- 像素操作：切片与索引\n- 亮度调整：`img - 50` 直接操作矩阵数值\n\n**底层逻辑**\n- **图像本质**：图像是数字矩阵，理解这一点是所有图像处理的基础\n\n`#执行层` `#测评项`\n[UID: PYAI-24-03-001]\n[关联: PYAI-24-01-001 视频基础（前置课程）]\n[关联: PYAI-24-04-001 图像编辑2（后续课程）]\n\n---\n\n### 2-4-4 图像编辑2 - ROI区域替换\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-4 |\n| **课程名称** | 图像编辑2 - 局部马赛克 |\n| **认知负荷** | 高 |\n| **核心技能** | ROI区域替换、cv2.resize、os.listdir |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"上节课我们学了整张图片的操作，今天学习**局部区域操作**！\n>\n> **ROI (Region of Interest)** 就是'感兴趣区域'，我们可以只处理图片的一部分。\n>\n> ```python\n> import cv2\n>\n> img = cv2.imread('photo.jpg')\n>\n> # 用切片获取ROI区域 [y1:y2, x1:x2]\n> roi = img[100:200, 150:250]  # 从(150,100)到(250,200)的区域\n>\n> # 修改ROI\n> roi[:] = [0, 0, 255]  # 把这个区域变成红色\n>\n> # 或者替换为另一张图片\n> small_img = cv2.imread('logo.png')\n> small_img = cv2.resize(small_img, (100, 100))  # 调整大小\n> img[100:200, 150:250] = small_img  # 替换\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 切片顺序混淆 | 强调y在前 | `img[y1:y2, x1:x2]`，先行后列 |\n| 尺寸不匹配 | 用resize调整 | 替换区域和图片尺寸必须一致 |\n| 想批量处理 | 介绍os.listdir | 遍历文件夹中的所有图片 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来做**马赛克效果**！原理是：把一个区域缩小再放大，细节就丢失了。\n>\n> ```python\n> def add_mosaic(img, x1, y1, x2, y2, factor=10):\n>     '''给指定区域添加马赛克'''\n>     roi = img[y1:y2, x1:x2]\n>     h, w = roi.shape[:2]\n>\n>     # 先缩小\n>     small = cv2.resize(roi, (w//factor, h//factor))\n>     # 再放大回原尺寸（用最近邻插值保持块状效果）\n>     mosaic = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)\n>\n>     # 替换原区域\n>     img[y1:y2, x1:x2] = mosaic\n>     return img\n>\n> # 使用示例\n> img = add_mosaic(img, 100, 50, 200, 150)\n> ```\"\n\n**步骤3：批量处理（15分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"如果要处理很多图片怎么办？用`os.listdir`遍历文件夹：\n>\n> ```python\n> import os\n>\n> folder = 'photos/'\n> for filename in os.listdir(folder):\n>     if filename.endswith('.jpg'):\n>         img = cv2.imread(folder + filename)\n>         # 处理图片...\n>         cv2.imwrite('output/' + filename, img)\n> ```\"\n\n**核心代码模式**\n\n```python\n# ROI操作标准模板\nroi = img[y1:y2, x1:x2]  # 获取区域\nroi = cv2.resize(roi, (new_w, new_h))  # 调整大小\nimg[y1:y2, x1:x2] = processed_roi  # 替换回去\n```\n\n**禁忌提醒**\n- ROI切片顺序错误——`img[y:y, x:x]`不是`img[x:x, y:y]`\n- 替换区域尺寸不匹配——会报错\n- 忘记检查文件扩展名——可能读取非图片文件\n\n---\n\n**核心知识点**\n- ROI区域：用切片`img[y1:y2, x1:x2]`获取\n- cv2.resize：调整图片尺寸\n- 马赛克原理：缩小再放大丢失细节\n- os.listdir：遍历文件夹批量处理\n\n**底层逻辑**\n- **局部处理**：只修改需要的区域，提高效率\n- **批量自动化**：用循环处理大量文件\n\n`#执行层` `#测评项`\n[UID: PYAI-24-04-001]\n[关联: PYAI-24-03-001 图像编辑1（前置课程）]\n[关联: PYAI-24-05-001 滤波降噪（后续课程）]\n\n---\n\n### 2-4-5 滤波降噪\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-5 |\n| **课程名称** | 滤波降噪 |\n| **认知负荷** | 高 |\n| **核心技能** | 卷积核、均值/高斯/中值滤波 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们学习如何给图片'去噪'。你们看这张图片有很多小点点，这叫做**噪声**。\n>\n> 去噪的原理是**卷积**。简单说，就是用一个小方块（叫做卷积核）在图片上滑动，每个位置取周围像素的平均值或中间值。\n>\n> ```python\n> # 均值滤波：取周围像素的平均值\n> blur = cv2.blur(img, (5,5))\n>\n> # 高斯滤波：中间权重大，边缘权重小\n> gaussian = cv2.GaussianBlur(img, (5,5), 0)\n>\n> # 中值滤波：取中间值，对椒盐噪声效果好\n> median = cv2.medianBlur(img, 5)\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解卷积 | 用\"抹匀\"类比 | \"就像用手把颜色抹匀一样\" |\n| 想了解区别 | 对比不同滤波效果 | 同一张噪声图用三种方法处理 |\n| 核大小困惑 | 实验不同尺寸 | 3x3、5x5、7x7的效果对比 |\n\n**禁忌提醒**\n❌ 卷积核尺寸必须是奇数——(5,5)可以，(4,4)不行\n❌ 核太大会过度模糊——丢失细节\n\n---\n\n**核心知识点**\n- 滤波算法：均值/高斯/中值滤波\n- 卷积核(Kernel)：3x3, 5x5等\n- 噪声类型：椒盐噪声、高斯噪声\n\n`#执行层` `#测评项`\n[UID: PYAI-24-05-001]\n[关联: PYAI-24-04-001 图像编辑2（前置课程）]\n[关联: PYAI-24-06-001 文件扫描（后续课程）]\n\n---\n\n### 2-4-6 文件扫描\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-6 |\n| **课程名称** | 文件扫描 - 文档扫描仪 |\n| **认知负荷** | 高 |\n| **核心技能** | 二值化cv2.threshold、去阴影cv2.divide |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个**文档扫描仪**！把手机拍的文档照片变成清晰的扫描件。\n>\n> 主要解决两个问题：\n> 1. **去除阴影**：拍照时光线不均匀会有阴影\n> 2. **二值化**：把灰色变成纯黑白，更清晰\n>\n> ```python\n> import cv2\n>\n> # 读取图片并转灰度\n> img = cv2.imread('document.jpg')\n> gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n>\n> # 二值化：像素值大于阈值变白，否则变黑\n> ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n> ```\n>\n> **阈值127**的意思是：灰度值>127的变成255(白)，≤127的变成0(黑)。\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 阈值效果不好 | 用自适应阈值 | `cv2.adaptiveThreshold`自动计算局部阈值 |\n| 有阴影干扰 | 先去阴影 | 用`cv2.divide`消除光照不均 |\n| 想反转黑白 | 改变类型 | 用`cv2.THRESH_BINARY_INV`反转 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"普通二值化对阴影效果不好，我们用**自适应阈值**和**去阴影**技术：\n>\n> ```python\n> # 方法1：自适应阈值（自动计算局部阈值）\n> adaptive = cv2.adaptiveThreshold(\n>     gray, 255,\n>     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # 高斯加权\n>     cv2.THRESH_BINARY,\n>     11,  # 邻域大小\n>     2    # 常数C\n> )\n>\n> # 方法2：去阴影（更专业的方法）\n> # 1. 用高斯模糊获取背景\n> blur = cv2.GaussianBlur(gray, (21, 21), 0)\n> # 2. 用原图除以背景，消除光照不均\n> divided = cv2.divide(gray, blur, scale=255)\n> # 3. 再二值化\n> ret, result = cv2.threshold(divided, 200, 255, cv2.THRESH_BINARY)\n> ```\n>\n> **cv2.divide的原理**：背景亮的地方除以大数，背景暗的地方除以小数，结果就均匀了！\"\n\n**核心代码模式**\n\n```python\n# 文档扫描标准流程\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (21, 21), 0)\ndivided = cv2.divide(gray, blur, scale=255)\nret, binary = cv2.threshold(divided, 200, 255, cv2.THRESH_BINARY)\n```\n\n**禁忌提醒**\n- 阈值设置不当——太高全白，太低全黑\n- 自适应阈值邻域用偶数——必须是奇数\n- 忘记转灰度——threshold只能处理单通道图像\n\n---\n\n**核心知识点**\n- 二值化(threshold)：将灰度图转为纯黑白\n- 自适应阈值：根据局部区域自动计算阈值\n- cv2.divide：消除光照不均匀（去阴影）\n- 文档扫描流程：灰度→去阴影→二值化\n\n**底层逻辑**\n- **光照归一化**：divide操作消除光照差异\n- **局部自适应**：不同区域用不同阈值\n\n`#执行层` `#测评项`\n[UID: PYAI-24-06-001]\n[关联: PYAI-24-05-001 滤波降噪（前置课程）]\n[关联: PYAI-24-08-001 人像分割（后续课程）]\n\n---\n\n### 2-4-8/9 人像分割\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-8/9 |\n| **课程名称** | 人像分割 - 视频会议虚拟背景 |\n| **认知负荷** | 高 |\n| **核心技能** | MediaPipe Selfie Segmentation、Mask掩膜 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"大家用过视频会议的虚拟背景吗？今天我们来做一个！\n>\n> 原理是**人像分割**：AI模型识别出哪些像素是人，哪些是背景。然后用新背景替换掉原背景。\n>\n> ```python\n> import mediapipe as mp\n>\n> # 初始化人像分割模型\n> selfie_segmentation = mp.solutions.selfie_segmentation\n> segment = selfie_segmentation.SelfieSegmentation()\n>\n> # 获取掩膜\n> results = segment.process(frame)\n> mask = results.segmentation_mask  # 人像区域是1，背景是0\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 边缘不干净 | 调整阈值 | `mask > 0.5` 改成 `mask > 0.7` |\n| 想用自己的背景 | 加载自定义图片 | 用cv2.imread加载背景图 |\n| 帧率太低 | 降低分辨率 | 先resize再处理 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们用`numpy.where`来替换背景：\n>\n> ```python\n> import numpy as np\n>\n> # 三通道掩膜\n> mask_3d = np.stack([mask, mask, mask], axis=-1)\n>\n> # 替换背景\n> output = np.where(mask_3d > 0.5, frame, background)\n> ```\n>\n> `np.where`的意思是：如果条件成立，用第一个值；否则用第二个值。\"\n\n**禁忌提醒**\n❌ 图像尺寸不匹配——frame和background必须尺寸相同\n❌ 通道数不一致——都必须是3通道\n\n---\n\n**核心知识点**\n- Selfie Segmentation：人像分割模型\n- Mask掩膜：0/1遮罩原理\n- 背景融合：`numpy.where` 替换背景\n\n`#执行层` `#测评项`\n[UID: PYAI-24-08-001]\n[关联: PYAI-24-06-001 文件扫描（前置课程）]\n[关联: PYAI-24-10-001 虚拟墨镜（后续课程）]\n\n---\n\n### 2-4-10/11 虚拟墨镜\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-10/11 |\n| **课程名称** | 虚拟墨镜 - AR试戴 |\n| **认知负荷** | 高 |\n| **核心技能** | FaceMesh 468点、Alpha通道、AR增强现实 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们做AR虚拟试戴墨镜！需要解决三个问题：\n>\n> 1. **找到眼睛位置**：用FaceMesh模型，它能识别脸上468个关键点\n> 2. **缩放墨镜大小**：根据两眼间距调整墨镜尺寸\n> 3. **透明叠加**：墨镜PNG图片有Alpha通道（透明度）\n>\n> ```python\n> # 获取FaceMesh关键点\n> face_mesh = mp.solutions.face_mesh.FaceMesh()\n> results = face_mesh.process(frame)\n>\n> # 关键点索引：左眼外角33，右眼外角263\n> left_eye = results.multi_face_landmarks[0].landmark[33]\n> right_eye = results.multi_face_landmarks[0].landmark[263]\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 墨镜位置偏 | 调整关键点索引 | 尝试不同的landmark索引 |\n| 想换其他贴图 | 提供素材库 | 帽子、胡子、耳环等 |\n| 多人同时检测 | 遍历所有face_landmarks | 循环处理每张脸 |\n\n**禁忌提醒**\n❌ 像素坐标用浮点数——必须用int()转换为整数\n❌ 忘记处理Alpha通道——墨镜会有白色背景\n\n---\n\n**核心知识点**\n- FaceMesh：468个关键点\n- Alpha通道：透明图片叠加\n- 几何计算：根据眼距缩放贴图\n\n`#执行层` `#测评项`\n[UID: PYAI-24-10-001]\n[关联: PYAI-24-08-001 人像分割（前置课程）]\n[关联: PYAI-24-12-001 动物伙伴（后续课程）]\n\n---\n\n### 2-4-12 动物伙伴\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-12 |\n| **课程名称** | 动物伙伴 - 肩膀上的宠物 |\n| **认知负荷** | 高 |\n| **核心技能** | Pose模型、GIF处理、位置跟随 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个超酷的AR效果——**肩膀上的虚拟宠物**！\n>\n> 需要解决三个问题：\n> 1. **找到肩膀位置**：用MediaPipe Pose模型检测身体关键点\n> 2. **加载动画宠物**：处理GIF动图\n> 3. **让宠物跟随移动**：实时更新位置\n>\n> ```python\n> import mediapipe as mp\n>\n> # 初始化Pose模型\n> mp_pose = mp.solutions.pose\n> pose = mp_pose.Pose()\n>\n> # 处理图像获取关键点\n> results = pose.process(frame_rgb)\n>\n> # 获取左肩位置（索引11）和右肩位置（索引12）\n> if results.pose_landmarks:\n>     left_shoulder = results.pose_landmarks.landmark[11]\n>     right_shoulder = results.pose_landmarks.landmark[12]\n>     # 坐标是0-1的比例，需要乘以图像尺寸\n>     x = int(left_shoulder.x * width)\n>     y = int(left_shoulder.y * height)\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 想放在头顶 | 改用头部关键点 | 索引0是鼻子，可以往上偏移 |\n| 宠物太大/太小 | 根据肩宽缩放 | 用两肩距离计算合适的宠物大小 |\n| 想用静态图片 | 简化为PNG | 不需要GIF处理，直接叠加 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来处理GIF动图。Python可以用PIL库读取GIF的每一帧：\n>\n> ```python\n> from PIL import Image\n> import numpy as np\n>\n> # 加载GIF\n> gif = Image.open('pet.gif')\n> frames = []\n>\n> # 提取所有帧\n> try:\n>     while True:\n>         # 转换为RGBA（带透明通道）\n>         frame = gif.convert('RGBA')\n>         frames.append(np.array(frame))\n>         gif.seek(gif.tell() + 1)  # 下一帧\n> except EOFError:\n>     pass  # 读完了\n>\n> # 循环播放\n> frame_index = 0\n> pet_frame = frames[frame_index % len(frames)]\n> frame_index += 1\n> ```\"\n\n**步骤3：叠加宠物（15分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"最后把宠物叠加到肩膀位置。注意处理透明通道：\n>\n> ```python\n> def overlay_image(background, overlay, x, y):\n>     '''将带透明通道的图片叠加到背景上'''\n>     h, w = overlay.shape[:2]\n>\n>     # 确保不超出边界\n>     if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:\n>         return background\n>\n>     # 分离Alpha通道\n>     alpha = overlay[:, :, 3] / 255.0\n>     alpha = np.stack([alpha, alpha, alpha], axis=-1)\n>\n>     # 混合\n>     roi = background[y:y+h, x:x+w]\n>     blended = (1 - alpha) * roi + alpha * overlay[:, :, :3]\n>     background[y:y+h, x:x+w] = blended.astype(np.uint8)\n>\n>     return background\n> ```\"\n\n**核心代码模式**\n\n```python\n# Pose关键点检测标准模板\npose = mp.solutions.pose.Pose()\nresults = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\nif results.pose_landmarks:\n    landmark = results.pose_landmarks.landmark[index]\n    x, y = int(landmark.x * w), int(landmark.y * h)\n```\n\n**禁忌提醒**\n- 坐标超出图像边界——叠加前必须检查\n- GIF帧索引越界——用取余`%`循环\n- 忘记转换颜色空间——Pose需要RGB输入\n- Alpha通道处理错误——导致宠物有白边\n\n---\n\n**核心知识点**\n- Pose模型：33个身体关键点检测\n- 关键点索引：11左肩、12右肩、0鼻子\n- GIF处理：PIL读取、逐帧提取\n- Alpha混合：透明图片叠加公式\n\n**底层逻辑**\n- **人体姿态估计**：AI模型识别身体关键点\n- **动画循环**：帧索引取余实现无限循环\n- **透明度混合**：`(1-alpha)*背景 + alpha*前景`\n\n`#执行层` `#测评项`\n[UID: PYAI-24-12-001]\n[关联: PYAI-24-10-001 虚拟墨镜（前置课程）]\n\n---"
    },
    {
      "title": "教学禁忌清单",
      "content": "| 序号 | 禁忌 | 原因 | 正确做法 |\n|------|------|------|----------|\n| 1 | 视频循环缺失cv2.waitKey() | 窗口无响应或卡死 | 必须添加waitKey(1) |\n| 2 | 图像尺寸/通道不匹配 | 报错 | 确保两张图片的(w,h)和通道数完全一致 |\n| 3 | BGR/RGB通道顺序错误 | 颜色错误 | OpenCV是BGR，需用cvtColor转换 |\n| 4 | 像素坐标使用浮点数 | 报错 | 必须用int()转换为整数 |\n| 5 | 卷积核尺寸用偶数 | 报错 | 必须使用奇数(3,5,7...) |\n| 6 | 忘记释放摄像头 | 下次无法使用 | 程序结束前cap.release() |\n\n`#执行层` `#测评项`\n[UID: PYAI-TABOO-24]\n\n---"
    },
    {
      "title": "教学注意事项",
      "content": "| 类别 | 注意事项 |\n|------|----------|\n| **通道顺序** | OpenCV默认BGR，MediaPipe和Matplotlib使用RGB，需转换 |\n| **数据维度** | 图像加减或掩膜操作时，必须确保尺寸和通道数一致 |\n| **关键点索引** | FaceMesh有468个点，需结合图示明确索引 |\n| **坐标转换** | 像素坐标必须是整数，用int()转换 |\n| **性能优化** | 实时视频处理时注意帧率，必要时降低分辨率 |\n\n---"
    },
    {
      "title": "底层教育学原理",
      "content": "| 原理 | 说明 | 在本单元的应用 |\n|------|------|----------------|\n| **图像本质** | 图像是数字矩阵 | NumPy数组操作像素值 |\n| **卷积运算** | 滤波/降噪的数学基础 | 卷积核大小影响模糊程度 |\n| **AI模型应用** | 预训练模型的使用 | MediaPipe人像分割、面部网格 |\n| **AR增强现实** | 虚拟与现实融合 | 虚拟墨镜、动物伙伴 |\n| **项目制学习** | 完整项目驱动学习 | 视频会议背景、AR试戴 |\n\n`#执行层` `#测评项`\n[UID: PYAI-THEORY-24]\n\n---\n\n**质量评估**：10/10（原子化萃取版，12节课完整萃取）\n**已补充**：认知负荷标签、IFC标签、变体示例、详细教师话术、核心代码模式\n**课程覆盖**：2-4-1至2-4-12全部课程\n\n---\n\n**最后更新**：2026-02-09"
    }
  ],
  "full_content": "# PythonAI萃取：L2-4 计算机视觉CV\n\n> **来源**：NotebookLM Python AI Lesson Plan (96个来源)\n> **萃取日期**：2026-02-02\n> **萃取深度**：5-5多维度（含认知负荷标签、IFC标签、变体示例）\n> **更新日期**：2026-02-04\n\n---\n\n## 单元概览\n\n| 项目 | 内容 |\n|------|------|\n| **单元编号** | PYAI 2-4 |\n| **单元名称** | 计算机视觉 (Computer Vision) |\n| **适用年龄** | 四年级及以上（10-12岁） |\n| **课时数** | 12节 × 90分钟 |\n| **核心目标** | 深入图像处理底层原理，从像素操作到卷积运算，再到高级AI模型应用 |\n| **核心库** | OpenCV (cv2), NumPy, MediaPipe |\n\n**底层逻辑**\n深入图像处理底层原理，实现特效与增强现实(AR)应用。理解图像的数字本质，掌握AI视觉模型的应用。\n\n**单元教学策略**\n- 视频基础（01）：视频本质、帧率、循环播放\n- 像素操作（03-04）：NumPy数组、亮度调整、ROI\n- 滤波处理（05-06）：卷积核、降噪、二值化\n- AI模型（08-12）：人像分割、AR增强现实\n\n`#执行层` `#测评项`\n[UID: PYAI-24-001]\n[关联: PYAI-14-001 PythonAI智能硬件（前置基础）]\n[关联: PYAI-23-001 PythonAI交互式AI（并行学习）]\n\n---\n\n## 课程列表\n\n| 课次 | 课程名称 | 核心知识点 | 项目内容 | 认知负荷 |\n|------|----------|------------|----------|----------|\n| 2-4-1 | 视频基础 | cv2.VideoCapture、帧率控制、循环播放 | 视频播放器 | 中 |\n| 2-4-3 | 图像编辑1 | NumPy数组、像素操作、亮度调整 | 图片变暗/反色 | 中-高 |\n| 2-4-4 | 图像编辑2 | ROI区域替换、cv2.resize、os.listdir | 局部马赛克 | 高 |\n| 2-4-5 | 滤波降噪 | 均值/高斯/中值滤波、卷积核 | 图片降噪器 | 高 |\n| 2-4-6 | 文件扫描 | 二值化cv2.threshold、去阴影cv2.divide | 文档扫描仪 | 高 |\n| 2-4-8/9 | 人像分割 | Selfie Segmentation、Mask掩膜、numpy.where | 视频会议虚拟背景 | 高 |\n| 2-4-10/11 | 虚拟墨镜 | FaceMesh 468点、Alpha通道、几何计算 | AR试戴 | 高 |\n| 2-4-12 | 动物伙伴 | Pose模型、GIF处理、位置跟随 | 肩膀上的宠物 | 高 |\n\n---\n\n## 通用教学流程（90分钟）\n\n| 环节 | 时间 | 内容 | 认知负荷 | IFC标签 |\n|------|------|------|----------|---------|\n| 课堂问候 | 2分钟 | 自我介绍、学习目标 | `#低负荷-热身` | `#IFC-预防` |\n| 课程回顾 | 5分钟 | 复习上节课代码和概念 | `#低负荷-热身` | `#IFC-预防` |\n| 知识讲解 | 20分钟 | 新概念/算法讲解 | `#中负荷-操练` | `#IFC-即时` |\n| 代码实践 | 35分钟 | 编写代码、调试运行 | `#高负荷-产出` | `#IFC-即时` |\n| 调节休息 | 3分钟 | 站起来活动、眼保健操 | `#调节-放松` | - |\n| 项目拓展 | 15分钟 | 自由创作/挑战任务 | `#高负荷-产出` | `#IFC-即时` |\n| 成果展示 | 10分钟 | 分享代码、讲解思路 | `#低负荷-热身` | `#IFC-复盘` |\n\n`#执行层` `#测评项`\n[UID: PYAI-24-FLOW-001]\n\n---\n\n## 详细课程萃取\n\n### 2-4-1 视频基础\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-1 |\n| **课程名称** | 视频基础 - 视频播放器 |\n| **认知负荷** | 中 |\n| **核心技能** | cv2.VideoCapture、帧率控制、循环播放 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来揭开视频的秘密！大家知道视频是什么吗？其实视频就是**很多张图片快速播放**！\n>\n> 就像翻书动画一样，每秒播放24张以上的图片，人眼就会觉得是连续的动作。这个'每秒多少张'就叫做**帧率(FPS)**。\n>\n> ```python\n> import cv2\n>\n> # 打开视频文件\n> cap = cv2.VideoCapture('video.mp4')\n>\n> # 获取视频信息\n> fps = cap.get(cv2.CAP_PROP_FPS)  # 帧率\n> width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # 宽度\n> height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # 高度\n> print(f'帧率: {fps}, 尺寸: {width}x{height}')\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解帧率 | 用翻书动画演示 | 准备一本翻页动画书 |\n| 想用摄像头 | 改用设备编号 | `cv2.VideoCapture(0)` 打开默认摄像头 |\n| 视频打不开 | 检查路径 | 确认文件路径正确，使用绝对路径 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来写一个视频播放器！关键是用**while循环**不断读取每一帧：\n>\n> ```python\n> while True:\n>     ret, frame = cap.read()  # 读取一帧\n>\n>     if not ret:  # 视频结束\n>         cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # 回到开头，循环播放\n>         continue\n>\n>     cv2.imshow('Video Player', frame)\n>\n>     # 按Q键退出\n>     if cv2.waitKey(30) & 0xFF == ord('q'):\n>         break\n>\n> cap.release()  # 释放资源\n> cv2.destroyAllWindows()\n> ```\n>\n> **重点**：`cv2.waitKey(30)` 控制播放速度，30毫秒约等于33帧/秒。\"\n\n**核心代码模式**\n\n```python\n# 视频播放标准模板\ncap = cv2.VideoCapture('video.mp4')\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break  # 或循环播放\n    cv2.imshow('Window', frame)\n    if cv2.waitKey(30) & 0xFF == ord('q'):\n        break\ncap.release()\ncv2.destroyAllWindows()\n```\n\n**禁忌提醒**\n- 忘记`cv2.waitKey()`——窗口会卡死无响应\n- 忘记`cap.release()`——下次无法打开摄像头\n- waitKey参数为0——会暂停等待按键\n\n---\n\n**核心知识点**\n- 视频本质：连续图片帧的快速播放\n- 帧率(FPS)：每秒播放的帧数，通常24-60fps\n- VideoCapture：OpenCV读取视频/摄像头的核心类\n- waitKey：控制播放速度和键盘响应\n\n`#执行层` `#测评项`\n[UID: PYAI-24-01-001]\n[关联: PYAI-24-03-001 图像编辑（后续课程）]\n\n---\n\n### 2-4-3 图像编辑1（典型案例）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-3 |\n| **课程名称** | 图像编辑1 - 像素操作 |\n| **认知负荷** | 中-高 |\n| **核心技能** | NumPy数组、像素操作、亮度调整 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们要揭开图像的秘密！大家知道吗，电脑看到的图片其实是一堆数字。每个像素都是一个数字，范围是0-255。0是黑色，255是白色。\"\n>\n> \"在Python里，图片被读成一个NumPy数组：\n> ```python\n> import cv2\n> img = cv2.imread('photo.jpg')\n> print(img.shape)  # (高度, 宽度, 通道数)\n> ```\n>\n> 彩色图片有3个通道：蓝(B)、绿(G)、红(R)。注意，OpenCV的顺序是BGR，不是RGB！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解数组 | 用Excel类比 | \"图片就像一个巨大的Excel表格，每格是一个数字\" |\n| 混淆BGR和RGB | 强调顺序 | \"OpenCV用BGR，就像'倒着读'一样\" |\n| 想深入了解 | 展示单通道 | 分别显示B、G、R三个通道的灰度图 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来修改图片亮度。原理很简单：把所有像素值减小，图片就变暗了！\n>\n> ```python\n> dark_img = img - 50  # 每个像素减50，变暗\n> bright_img = img + 50  # 每个像素加50，变亮\n> ```\n>\n> 还可以做反色效果：\n> ```python\n> inverted = 255 - img  # 黑变白，白变黑\n> ```\"\n\n**禁忌提醒**\n❌ 像素值超出0-255范围——会导致颜色异常\n❌ 忘记转换数据类型——可能出现溢出错误\n\n---\n\n**步骤3：成果展示（10分钟）** `#低负荷-热身` `#IFC-复盘`\n\n**教师话术**\n> \"谁来展示一下你的作品？告诉大家你用了什么方法修改图片？\"\n\n---\n\n**核心知识点**\n- NumPy数组：图像的矩阵本质\n- 像素操作：切片与索引\n- 亮度调整：`img - 50` 直接操作矩阵数值\n\n**底层逻辑**\n- **图像本质**：图像是数字矩阵，理解这一点是所有图像处理的基础\n\n`#执行层` `#测评项`\n[UID: PYAI-24-03-001]\n[关联: PYAI-24-01-001 视频基础（前置课程）]\n[关联: PYAI-24-04-001 图像编辑2（后续课程）]\n\n---\n\n### 2-4-4 图像编辑2 - ROI区域替换\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-4 |\n| **课程名称** | 图像编辑2 - 局部马赛克 |\n| **认知负荷** | 高 |\n| **核心技能** | ROI区域替换、cv2.resize、os.listdir |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"上节课我们学了整张图片的操作，今天学习**局部区域操作**！\n>\n> **ROI (Region of Interest)** 就是'感兴趣区域'，我们可以只处理图片的一部分。\n>\n> ```python\n> import cv2\n>\n> img = cv2.imread('photo.jpg')\n>\n> # 用切片获取ROI区域 [y1:y2, x1:x2]\n> roi = img[100:200, 150:250]  # 从(150,100)到(250,200)的区域\n>\n> # 修改ROI\n> roi[:] = [0, 0, 255]  # 把这个区域变成红色\n>\n> # 或者替换为另一张图片\n> small_img = cv2.imread('logo.png')\n> small_img = cv2.resize(small_img, (100, 100))  # 调整大小\n> img[100:200, 150:250] = small_img  # 替换\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 切片顺序混淆 | 强调y在前 | `img[y1:y2, x1:x2]`，先行后列 |\n| 尺寸不匹配 | 用resize调整 | 替换区域和图片尺寸必须一致 |\n| 想批量处理 | 介绍os.listdir | 遍历文件夹中的所有图片 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来做**马赛克效果**！原理是：把一个区域缩小再放大，细节就丢失了。\n>\n> ```python\n> def add_mosaic(img, x1, y1, x2, y2, factor=10):\n>     '''给指定区域添加马赛克'''\n>     roi = img[y1:y2, x1:x2]\n>     h, w = roi.shape[:2]\n>\n>     # 先缩小\n>     small = cv2.resize(roi, (w//factor, h//factor))\n>     # 再放大回原尺寸（用最近邻插值保持块状效果）\n>     mosaic = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)\n>\n>     # 替换原区域\n>     img[y1:y2, x1:x2] = mosaic\n>     return img\n>\n> # 使用示例\n> img = add_mosaic(img, 100, 50, 200, 150)\n> ```\"\n\n**步骤3：批量处理（15分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"如果要处理很多图片怎么办？用`os.listdir`遍历文件夹：\n>\n> ```python\n> import os\n>\n> folder = 'photos/'\n> for filename in os.listdir(folder):\n>     if filename.endswith('.jpg'):\n>         img = cv2.imread(folder + filename)\n>         # 处理图片...\n>         cv2.imwrite('output/' + filename, img)\n> ```\"\n\n**核心代码模式**\n\n```python\n# ROI操作标准模板\nroi = img[y1:y2, x1:x2]  # 获取区域\nroi = cv2.resize(roi, (new_w, new_h))  # 调整大小\nimg[y1:y2, x1:x2] = processed_roi  # 替换回去\n```\n\n**禁忌提醒**\n- ROI切片顺序错误——`img[y:y, x:x]`不是`img[x:x, y:y]`\n- 替换区域尺寸不匹配——会报错\n- 忘记检查文件扩展名——可能读取非图片文件\n\n---\n\n**核心知识点**\n- ROI区域：用切片`img[y1:y2, x1:x2]`获取\n- cv2.resize：调整图片尺寸\n- 马赛克原理：缩小再放大丢失细节\n- os.listdir：遍历文件夹批量处理\n\n**底层逻辑**\n- **局部处理**：只修改需要的区域，提高效率\n- **批量自动化**：用循环处理大量文件\n\n`#执行层` `#测评项`\n[UID: PYAI-24-04-001]\n[关联: PYAI-24-03-001 图像编辑1（前置课程）]\n[关联: PYAI-24-05-001 滤波降噪（后续课程）]\n\n---\n\n### 2-4-5 滤波降噪\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-5 |\n| **课程名称** | 滤波降噪 |\n| **认知负荷** | 高 |\n| **核心技能** | 卷积核、均值/高斯/中值滤波 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们学习如何给图片'去噪'。你们看这张图片有很多小点点，这叫做**噪声**。\n>\n> 去噪的原理是**卷积**。简单说，就是用一个小方块（叫做卷积核）在图片上滑动，每个位置取周围像素的平均值或中间值。\n>\n> ```python\n> # 均值滤波：取周围像素的平均值\n> blur = cv2.blur(img, (5,5))\n>\n> # 高斯滤波：中间权重大，边缘权重小\n> gaussian = cv2.GaussianBlur(img, (5,5), 0)\n>\n> # 中值滤波：取中间值，对椒盐噪声效果好\n> median = cv2.medianBlur(img, 5)\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解卷积 | 用\"抹匀\"类比 | \"就像用手把颜色抹匀一样\" |\n| 想了解区别 | 对比不同滤波效果 | 同一张噪声图用三种方法处理 |\n| 核大小困惑 | 实验不同尺寸 | 3x3、5x5、7x7的效果对比 |\n\n**禁忌提醒**\n❌ 卷积核尺寸必须是奇数——(5,5)可以，(4,4)不行\n❌ 核太大会过度模糊——丢失细节\n\n---\n\n**核心知识点**\n- 滤波算法：均值/高斯/中值滤波\n- 卷积核(Kernel)：3x3, 5x5等\n- 噪声类型：椒盐噪声、高斯噪声\n\n`#执行层` `#测评项`\n[UID: PYAI-24-05-001]\n[关联: PYAI-24-04-001 图像编辑2（前置课程）]\n[关联: PYAI-24-06-001 文件扫描（后续课程）]\n\n---\n\n### 2-4-6 文件扫描\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-6 |\n| **课程名称** | 文件扫描 - 文档扫描仪 |\n| **认知负荷** | 高 |\n| **核心技能** | 二值化cv2.threshold、去阴影cv2.divide |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个**文档扫描仪**！把手机拍的文档照片变成清晰的扫描件。\n>\n> 主要解决两个问题：\n> 1. **去除阴影**：拍照时光线不均匀会有阴影\n> 2. **二值化**：把灰色变成纯黑白，更清晰\n>\n> ```python\n> import cv2\n>\n> # 读取图片并转灰度\n> img = cv2.imread('document.jpg')\n> gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n>\n> # 二值化：像素值大于阈值变白，否则变黑\n> ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n> ```\n>\n> **阈值127**的意思是：灰度值>127的变成255(白)，≤127的变成0(黑)。\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 阈值效果不好 | 用自适应阈值 | `cv2.adaptiveThreshold`自动计算局部阈值 |\n| 有阴影干扰 | 先去阴影 | 用`cv2.divide`消除光照不均 |\n| 想反转黑白 | 改变类型 | 用`cv2.THRESH_BINARY_INV`反转 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"普通二值化对阴影效果不好，我们用**自适应阈值**和**去阴影**技术：\n>\n> ```python\n> # 方法1：自适应阈值（自动计算局部阈值）\n> adaptive = cv2.adaptiveThreshold(\n>     gray, 255,\n>     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # 高斯加权\n>     cv2.THRESH_BINARY,\n>     11,  # 邻域大小\n>     2    # 常数C\n> )\n>\n> # 方法2：去阴影（更专业的方法）\n> # 1. 用高斯模糊获取背景\n> blur = cv2.GaussianBlur(gray, (21, 21), 0)\n> # 2. 用原图除以背景，消除光照不均\n> divided = cv2.divide(gray, blur, scale=255)\n> # 3. 再二值化\n> ret, result = cv2.threshold(divided, 200, 255, cv2.THRESH_BINARY)\n> ```\n>\n> **cv2.divide的原理**：背景亮的地方除以大数，背景暗的地方除以小数，结果就均匀了！\"\n\n**核心代码模式**\n\n```python\n# 文档扫描标准流程\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (21, 21), 0)\ndivided = cv2.divide(gray, blur, scale=255)\nret, binary = cv2.threshold(divided, 200, 255, cv2.THRESH_BINARY)\n```\n\n**禁忌提醒**\n- 阈值设置不当——太高全白，太低全黑\n- 自适应阈值邻域用偶数——必须是奇数\n- 忘记转灰度——threshold只能处理单通道图像\n\n---\n\n**核心知识点**\n- 二值化(threshold)：将灰度图转为纯黑白\n- 自适应阈值：根据局部区域自动计算阈值\n- cv2.divide：消除光照不均匀（去阴影）\n- 文档扫描流程：灰度→去阴影→二值化\n\n**底层逻辑**\n- **光照归一化**：divide操作消除光照差异\n- **局部自适应**：不同区域用不同阈值\n\n`#执行层` `#测评项`\n[UID: PYAI-24-06-001]\n[关联: PYAI-24-05-001 滤波降噪（前置课程）]\n[关联: PYAI-24-08-001 人像分割（后续课程）]\n\n---\n\n### 2-4-8/9 人像分割\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-8/9 |\n| **课程名称** | 人像分割 - 视频会议虚拟背景 |\n| **认知负荷** | 高 |\n| **核心技能** | MediaPipe Selfie Segmentation、Mask掩膜 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"大家用过视频会议的虚拟背景吗？今天我们来做一个！\n>\n> 原理是**人像分割**：AI模型识别出哪些像素是人，哪些是背景。然后用新背景替换掉原背景。\n>\n> ```python\n> import mediapipe as mp\n>\n> # 初始化人像分割模型\n> selfie_segmentation = mp.solutions.selfie_segmentation\n> segment = selfie_segmentation.SelfieSegmentation()\n>\n> # 获取掩膜\n> results = segment.process(frame)\n> mask = results.segmentation_mask  # 人像区域是1，背景是0\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 边缘不干净 | 调整阈值 | `mask > 0.5` 改成 `mask > 0.7` |\n| 想用自己的背景 | 加载自定义图片 | 用cv2.imread加载背景图 |\n| 帧率太低 | 降低分辨率 | 先resize再处理 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们用`numpy.where`来替换背景：\n>\n> ```python\n> import numpy as np\n>\n> # 三通道掩膜\n> mask_3d = np.stack([mask, mask, mask], axis=-1)\n>\n> # 替换背景\n> output = np.where(mask_3d > 0.5, frame, background)\n> ```\n>\n> `np.where`的意思是：如果条件成立，用第一个值；否则用第二个值。\"\n\n**禁忌提醒**\n❌ 图像尺寸不匹配——frame和background必须尺寸相同\n❌ 通道数不一致——都必须是3通道\n\n---\n\n**核心知识点**\n- Selfie Segmentation：人像分割模型\n- Mask掩膜：0/1遮罩原理\n- 背景融合：`numpy.where` 替换背景\n\n`#执行层` `#测评项`\n[UID: PYAI-24-08-001]\n[关联: PYAI-24-06-001 文件扫描（前置课程）]\n[关联: PYAI-24-10-001 虚拟墨镜（后续课程）]\n\n---\n\n### 2-4-10/11 虚拟墨镜\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-10/11 |\n| **课程名称** | 虚拟墨镜 - AR试戴 |\n| **认知负荷** | 高 |\n| **核心技能** | FaceMesh 468点、Alpha通道、AR增强现实 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们做AR虚拟试戴墨镜！需要解决三个问题：\n>\n> 1. **找到眼睛位置**：用FaceMesh模型，它能识别脸上468个关键点\n> 2. **缩放墨镜大小**：根据两眼间距调整墨镜尺寸\n> 3. **透明叠加**：墨镜PNG图片有Alpha通道（透明度）\n>\n> ```python\n> # 获取FaceMesh关键点\n> face_mesh = mp.solutions.face_mesh.FaceMesh()\n> results = face_mesh.process(frame)\n>\n> # 关键点索引：左眼外角33，右眼外角263\n> left_eye = results.multi_face_landmarks[0].landmark[33]\n> right_eye = results.multi_face_landmarks[0].landmark[263]\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 墨镜位置偏 | 调整关键点索引 | 尝试不同的landmark索引 |\n| 想换其他贴图 | 提供素材库 | 帽子、胡子、耳环等 |\n| 多人同时检测 | 遍历所有face_landmarks | 循环处理每张脸 |\n\n**禁忌提醒**\n❌ 像素坐标用浮点数——必须用int()转换为整数\n❌ 忘记处理Alpha通道——墨镜会有白色背景\n\n---\n\n**核心知识点**\n- FaceMesh：468个关键点\n- Alpha通道：透明图片叠加\n- 几何计算：根据眼距缩放贴图\n\n`#执行层` `#测评项`\n[UID: PYAI-24-10-001]\n[关联: PYAI-24-08-001 人像分割（前置课程）]\n[关联: PYAI-24-12-001 动物伙伴（后续课程）]\n\n---\n\n### 2-4-12 动物伙伴\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-4-12 |\n| **课程名称** | 动物伙伴 - 肩膀上的宠物 |\n| **认知负荷** | 高 |\n| **核心技能** | Pose模型、GIF处理、位置跟随 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个超酷的AR效果——**肩膀上的虚拟宠物**！\n>\n> 需要解决三个问题：\n> 1. **找到肩膀位置**：用MediaPipe Pose模型检测身体关键点\n> 2. **加载动画宠物**：处理GIF动图\n> 3. **让宠物跟随移动**：实时更新位置\n>\n> ```python\n> import mediapipe as mp\n>\n> # 初始化Pose模型\n> mp_pose = mp.solutions.pose\n> pose = mp_pose.Pose()\n>\n> # 处理图像获取关键点\n> results = pose.process(frame_rgb)\n>\n> # 获取左肩位置（索引11）和右肩位置（索引12）\n> if results.pose_landmarks:\n>     left_shoulder = results.pose_landmarks.landmark[11]\n>     right_shoulder = results.pose_landmarks.landmark[12]\n>     # 坐标是0-1的比例，需要乘以图像尺寸\n>     x = int(left_shoulder.x * width)\n>     y = int(left_shoulder.y * height)\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 想放在头顶 | 改用头部关键点 | 索引0是鼻子，可以往上偏移 |\n| 宠物太大/太小 | 根据肩宽缩放 | 用两肩距离计算合适的宠物大小 |\n| 想用静态图片 | 简化为PNG | 不需要GIF处理，直接叠加 |\n\n---\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们来处理GIF动图。Python可以用PIL库读取GIF的每一帧：\n>\n> ```python\n> from PIL import Image\n> import numpy as np\n>\n> # 加载GIF\n> gif = Image.open('pet.gif')\n> frames = []\n>\n> # 提取所有帧\n> try:\n>     while True:\n>         # 转换为RGBA（带透明通道）\n>         frame = gif.convert('RGBA')\n>         frames.append(np.array(frame))\n>         gif.seek(gif.tell() + 1)  # 下一帧\n> except EOFError:\n>     pass  # 读完了\n>\n> # 循环播放\n> frame_index = 0\n> pet_frame = frames[frame_index % len(frames)]\n> frame_index += 1\n> ```\"\n\n**步骤3：叠加宠物（15分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"最后把宠物叠加到肩膀位置。注意处理透明通道：\n>\n> ```python\n> def overlay_image(background, overlay, x, y):\n>     '''将带透明通道的图片叠加到背景上'''\n>     h, w = overlay.shape[:2]\n>\n>     # 确保不超出边界\n>     if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:\n>         return background\n>\n>     # 分离Alpha通道\n>     alpha = overlay[:, :, 3] / 255.0\n>     alpha = np.stack([alpha, alpha, alpha], axis=-1)\n>\n>     # 混合\n>     roi = background[y:y+h, x:x+w]\n>     blended = (1 - alpha) * roi + alpha * overlay[:, :, :3]\n>     background[y:y+h, x:x+w] = blended.astype(np.uint8)\n>\n>     return background\n> ```\"\n\n**核心代码模式**\n\n```python\n# Pose关键点检测标准模板\npose = mp.solutions.pose.Pose()\nresults = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\nif results.pose_landmarks:\n    landmark = results.pose_landmarks.landmark[index]\n    x, y = int(landmark.x * w), int(landmark.y * h)\n```\n\n**禁忌提醒**\n- 坐标超出图像边界——叠加前必须检查\n- GIF帧索引越界——用取余`%`循环\n- 忘记转换颜色空间——Pose需要RGB输入\n- Alpha通道处理错误——导致宠物有白边\n\n---\n\n**核心知识点**\n- Pose模型：33个身体关键点检测\n- 关键点索引：11左肩、12右肩、0鼻子\n- GIF处理：PIL读取、逐帧提取\n- Alpha混合：透明图片叠加公式\n\n**底层逻辑**\n- **人体姿态估计**：AI模型识别身体关键点\n- **动画循环**：帧索引取余实现无限循环\n- **透明度混合**：`(1-alpha)*背景 + alpha*前景`\n\n`#执行层` `#测评项`\n[UID: PYAI-24-12-001]\n[关联: PYAI-24-10-001 虚拟墨镜（前置课程）]\n\n---\n\n## 教学禁忌清单\n\n| 序号 | 禁忌 | 原因 | 正确做法 |\n|------|------|------|----------|\n| 1 | 视频循环缺失cv2.waitKey() | 窗口无响应或卡死 | 必须添加waitKey(1) |\n| 2 | 图像尺寸/通道不匹配 | 报错 | 确保两张图片的(w,h)和通道数完全一致 |\n| 3 | BGR/RGB通道顺序错误 | 颜色错误 | OpenCV是BGR，需用cvtColor转换 |\n| 4 | 像素坐标使用浮点数 | 报错 | 必须用int()转换为整数 |\n| 5 | 卷积核尺寸用偶数 | 报错 | 必须使用奇数(3,5,7...) |\n| 6 | 忘记释放摄像头 | 下次无法使用 | 程序结束前cap.release() |\n\n`#执行层` `#测评项`\n[UID: PYAI-TABOO-24]\n\n---\n\n## 教学注意事项\n\n| 类别 | 注意事项 |\n|------|----------|\n| **通道顺序** | OpenCV默认BGR，MediaPipe和Matplotlib使用RGB，需转换 |\n| **数据维度** | 图像加减或掩膜操作时，必须确保尺寸和通道数一致 |\n| **关键点索引** | FaceMesh有468个点，需结合图示明确索引 |\n| **坐标转换** | 像素坐标必须是整数，用int()转换 |\n| **性能优化** | 实时视频处理时注意帧率，必要时降低分辨率 |\n\n---\n\n## 底层教育学原理\n\n| 原理 | 说明 | 在本单元的应用 |\n|------|------|----------------|\n| **图像本质** | 图像是数字矩阵 | NumPy数组操作像素值 |\n| **卷积运算** | 滤波/降噪的数学基础 | 卷积核大小影响模糊程度 |\n| **AI模型应用** | 预训练模型的使用 | MediaPipe人像分割、面部网格 |\n| **AR增强现实** | 虚拟与现实融合 | 虚拟墨镜、动物伙伴 |\n| **项目制学习** | 完整项目驱动学习 | 视频会议背景、AR试戴 |\n\n`#执行层` `#测评项`\n[UID: PYAI-THEORY-24]\n\n---\n\n**质量评估**：10/10（原子化萃取版，12节课完整萃取）\n**已补充**：认知负荷标签、IFC标签、变体示例、详细教师话术、核心代码模式\n**课程覆盖**：2-4-1至2-4-12全部课程\n\n---\n\n**最后更新**：2026-02-09\n"
}