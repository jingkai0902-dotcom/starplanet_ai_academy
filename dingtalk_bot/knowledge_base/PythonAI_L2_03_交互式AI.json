{
  "title": "PythonAI萃取：L2-3 交互式AI与仿生控制",
  "source": "C:\\Users\\Frank.J\\starplanet_ai_academy\\知识库\\萃取报告\\PythonAI\\L2_03_交互式AI.md",
  "sections": [
    {
      "title": "单元概览",
      "content": "| 项目 | 内容 |\n|------|------|\n| **单元编号** | PYAI 2-3 |\n| **单元名称** | 交互式AI与仿生控制 |\n| **适用年龄** | 四年级及以上（10-12岁） |\n| **课时数** | 11节 × 90分钟 |\n| **核心目标** | 结合MediaPipe视觉模型与硬件控制，实现AIoT闭环 |\n| **核心库** | MediaPipe (FaceMesh, Hands), pygame, OpenCV |\n\n**底层逻辑**\n实现\"视觉识别-逻辑判断-硬件执行\"的AIoT闭环，培养AI应用能力。\n\n**单元教学策略**\n- 面部检测（01-02）：FaceMesh、眨眼检测\n- 表情识别（05）：关键点特征提取\n- 手势控制（07-11）：Hands模型、猜拳游戏\n\n`#执行层` `#测评项`\n[UID: PYAI-23-001]\n[关联: PYAI-14-001 PythonAI智能硬件（前置基础）]\n[关联: PYAI-24-001 PythonAI计算机视觉（并行学习）]\n\n---"
    },
    {
      "title": "课程列表",
      "content": "| 课次 | 课程名称 | 核心知识点 | 项目内容 | 认知负荷 |\n|------|----------|------------|----------|----------|\n| 2-3-1 | 眼控开关1 | MediaPipe FaceMesh、enumerate()、abs()/int() | 眨眼检测基础 | 高 |\n| 2-3-2 | 眼控开关2 | 阈值判定、状态机逻辑、cv2.putText | 智能灯控 | 高 |\n| 2-3-3 | 眼控开关3 | 状态机设计、防抖动处理、GPIO控制 | 眨眼控制进阶 | 高 |\n| 2-3-4 | 眼控开关4 | 多功能眼控、UI反馈、项目整合 | 眼控智能家居 | 高 |\n| 2-3-5 | 表情控制 | 关键点特征、pygame音频播放 | 表情音乐播放器 | 高 |\n| 2-3-6 | 表情控制进阶 | 多表情识别、表情强度计算、pygame界面 | 表情仪表盘 | 高 |\n| 2-3-7 | 手势识别 | MediaPipe Hands、21个关键点 | 手势判定 | 高 |\n| 2-3-8 | 手势控制应用 | 手势映射、pygame交互控制 | 手势控制游戏 | 高 |\n| 2-3-9 | 手势绘画板 | 指尖追踪、轨迹绘制、颜色切换 | 空中绘画 | 高 |\n| 2-3-10 | 机械手游戏(1) | random库、石头剪刀布判定 | 猜拳机器人 | 中-高 |\n| 2-3-11 | 机械手游戏(2) | random.choices()权重随机、概率算法 | 无敌猜拳王 | 高 |\n\n---"
    },
    {
      "title": "通用教学流程（90分钟）",
      "content": "| 环节 | 时间 | 内容 | 认知负荷 | IFC标签 |\n|------|------|------|----------|---------|\n| 课堂问候 | 2分钟 | 自我介绍、学习目标 | `#低负荷-热身` | `#IFC-预防` |\n| 课程回顾 | 5分钟 | 复习上节课代码知识 | `#低负荷-热身` | `#IFC-预防` |\n| 知识讲解 | 20分钟 | 新AI模型/概念讲解 | `#中负荷-操练` | `#IFC-即时` |\n| 代码实践 | 35分钟 | 编写代码、调试 | `#高负荷-产出` | `#IFC-即时` |\n| 调节休息 | 3分钟 | 站起来活动、眼保健操 | `#调节-放松` | - |\n| 项目拓展 | 15分钟 | 综合应用/挑战 | `#高负荷-产出` | `#IFC-即时` |\n| 成果展示 | 10分钟 | 分享代码、讲解思路 | `#低负荷-热身` | `#IFC-复盘` |\n\n`#执行层` `#测评项`\n[UID: PYAI-23-FLOW-001]\n\n---"
    },
    {
      "title": "详细课程萃取",
      "content": "### 2-3-1~2 眼控开关（典型案例）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-1/2 |\n| **课程名称** | 眼控开关 |\n| **认知负荷** | 高 |\n| **核心技能** | FaceMesh、眨眼检测、阈值判定 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个神奇的功能——**眨眼开灯**！用眼睛控制开关，是不是很酷？\"\n>\n> \"原理是用**FaceMesh**检测面部468个关键点，计算上下眼睑的距离：\n> ```python\n> import mediapipe as mp\n>\n> face_mesh = mp.solutions.face_mesh.FaceMesh()\n> results = face_mesh.process(frame)\n>\n> # 获取眼睛关键点\n> upper_lid = results.multi_face_landmarks[0].landmark[159]\n> lower_lid = results.multi_face_landmarks[0].landmark[145]\n>\n> # 计算眼睛开合度\n> eye_distance = abs(upper_lid.y - lower_lid.y)\n> ```\n>\n> 当距离小于阈值（比如0.01），判定为闭眼！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 阈值不准 | 实测调整 | 打印eye_distance观察正常值 |\n| 想检测嘴巴 | 换关键点 | 用嘴唇的关键点检测张嘴 |\n| 检测不稳定 | 添加滤波 | 连续N帧闭眼才判定为闭眼 |\n\n---\n\n**核心知识点**\n- FaceMesh：面部网格模型，468个关键点\n- 眨眼检测：计算上下眼睑关键点的垂直距离\n- 阈值判定：距离差 < 阈值 → 判定为闭眼\n\n`#执行层` `#测评项`\n[UID: PYAI-23-01-001]\n\n---\n\n### 2-3-3 眼控开关3（进阶）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-3 |\n| **课程名称** | 眼控开关3（进阶） |\n| **认知负荷** | 高 |\n| **核心技能** | 状态机设计、防抖动处理、GPIO控制 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"前两节课我们实现了眨眼检测，但有个问题——眨眼太快会误触发！今天学习**状态机**和**防抖动**。\"\n>\n> \"**状态机设计**：用变量记录当前状态\n> ```python\n> # 状态定义\n> STATE_OPEN = 0   # 眼睛睁开\n> STATE_CLOSED = 1 # 眼睛闭合\n> current_state = STATE_OPEN\n> blink_count = 0\n>\n> # 状态转换逻辑\n> if eye_distance < threshold:\n>     if current_state == STATE_OPEN:\n>         current_state = STATE_CLOSED\n>         blink_count += 1\n> else:\n>     current_state = STATE_OPEN\n> ```\n>\n> **防抖动处理**：连续N帧才确认状态变化\n> ```python\n> close_frames = 0\n> DEBOUNCE_FRAMES = 3  # 连续3帧才确认\n>\n> if eye_distance < threshold:\n>     close_frames += 1\n>     if close_frames >= DEBOUNCE_FRAMES:\n>         # 确认闭眼\n>         trigger_action()\n> else:\n>     close_frames = 0\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们把眨眼检测和硬件控制结合起来！\n> 眨眼一次开灯，再眨眼一次关灯。\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 状态切换太快 | 增加防抖帧数 | 把DEBOUNCE_FRAMES改为5 |\n| 想用双眨眼触发 | 添加计数器 | 1秒内眨眼2次才触发 |\n| 没有硬件 | 用屏幕模拟 | 用pygame画一个灯泡 |\n\n---\n\n**核心代码模式**\n```python\n# 完整的眨眼控制状态机\nclass BlinkController:\n    def __init__(self, threshold=0.01, debounce=3):\n        self.threshold = threshold\n        self.debounce = debounce\n        self.close_frames = 0\n        self.light_on = False\n\n    def update(self, eye_distance):\n        if eye_distance < self.threshold:\n            self.close_frames += 1\n            if self.close_frames == self.debounce:\n                self.light_on = not self.light_on\n                return self.light_on\n        else:\n            self.close_frames = 0\n        return None  # 无状态变化\n```\n\n**核心知识点**\n- 状态机：用变量记录和管理程序状态\n- 防抖动：连续N帧确认，避免误触发\n- 边沿检测：只在状态变化时触发动作\n\n`#执行层` `#测评项`\n[UID: PYAI-23-03-001]\n\n---\n\n### 2-3-4 眼控开关4（综合应用）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-4 |\n| **课程名称** | 眼控开关4（综合应用） |\n| **认知负荷** | 高 |\n| **核心技能** | 多功能眼控、UI反馈、项目整合 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们把前三节课的内容整合成一个完整的**眼控系统**！\n>\n> **功能设计**：\n> - 眨眼1次：开/关灯\n> - 眨眼2次：切换模式\n> - 长闭眼（2秒）：紧急停止\n>\n> **UI反馈设计**：\n> ```python\n> import cv2\n>\n> def draw_ui(frame, light_on, mode):\n>     # 绘制状态指示\n>     color = (0, 255, 0) if light_on else (0, 0, 255)\n>     cv2.circle(frame, (50, 50), 20, color, -1)\n>\n>     # 显示当前模式\n>     cv2.putText(frame, f'Mode: {mode}', (100, 50),\n>                 cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n>     return frame\n> ```\"\n\n**步骤2：项目整合（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在把所有功能整合到一个程序中，创建你的眼控智能家居系统！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 功能太多记不住 | 简化功能 | 先只做开关灯，再逐步添加 |\n| 想加声音提示 | 用pygame | pygame.mixer播放提示音 |\n| 想控制多个设备 | 扩展状态 | 用列表管理多个设备状态 |\n\n---\n\n**核心知识点**\n- 项目整合：将多个功能模块组合成完整系统\n- UI反馈：用视觉元素显示系统状态\n- 多功能触发：不同操作触发不同功能\n\n`#执行层` `#测评项`\n[UID: PYAI-23-04-001]\n\n---\n\n### 2-3-5 表情控制\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-5 |\n| **课程名称** | 表情控制 |\n| **认知负荷** | 高 |\n| **核心技能** | 关键点特征提取、pygame音频播放 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们用FaceMesh识别表情！不同表情会播放不同音乐。\"\n>\n> \"**表情识别原理**：通过关键点的相对位置判断表情\n>\n> **嘴巴张开检测**：\n> ```python\n> # 上嘴唇和下嘴唇的关键点\n> upper_lip = landmarks[13]  # 上嘴唇中点\n> lower_lip = landmarks[14]  # 下嘴唇中点\n>\n> mouth_open = abs(upper_lip.y - lower_lip.y)\n> if mouth_open > 0.05:\n>     print('嘴巴张开了！')\n> ```\n>\n> **微笑检测**：\n> ```python\n> # 嘴角的关键点\n> left_corner = landmarks[61]   # 左嘴角\n> right_corner = landmarks[291] # 右嘴角\n> mouth_center = landmarks[13]  # 嘴唇中点\n>\n> # 嘴角上扬 = 微笑\n> if left_corner.y < mouth_center.y and right_corner.y < mouth_center.y:\n>     print('检测到微笑！')\n> ```\"\n\n**步骤2：pygame音频播放（15分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"学习用pygame播放音乐：\n> ```python\n> import pygame\n>\n> pygame.mixer.init()\n>\n> # 加载音乐\n> happy_music = pygame.mixer.Sound('happy.wav')\n> sad_music = pygame.mixer.Sound('sad.wav')\n>\n> # 播放音乐\n> if is_smiling:\n>     happy_music.play()\n> elif is_mouth_open:\n>     sad_music.play()\n> ```\"\n\n**步骤3：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建一个表情音乐播放器：\n> - 微笑 → 播放欢快音乐\n> - 张嘴 → 播放惊讶音效\n> - 皱眉 → 播放悲伤音乐\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 关键点索引记不住 | 提供索引表 | 打印常用关键点索引对照表 |\n| 音乐文件找不到 | 检查路径 | 使用绝对路径或放在同一目录 |\n| 表情识别不准 | 调整阈值 | 打印数值，根据实际情况调整 |\n| 想识别更多表情 | 组合特征 | 眉毛+嘴巴组合判断复杂表情 |\n\n---\n\n**核心代码模式**\n```python\n# 表情音乐播放器完整代码框架\nimport cv2\nimport mediapipe as mp\nimport pygame\n\npygame.mixer.init()\n\nclass ExpressionMusicPlayer:\n    def __init__(self):\n        self.face_mesh = mp.solutions.face_mesh.FaceMesh()\n        self.sounds = {\n            'smile': pygame.mixer.Sound('happy.wav'),\n            'surprise': pygame.mixer.Sound('surprise.wav')\n        }\n        self.last_expression = None\n\n    def detect_expression(self, landmarks):\n        # 嘴巴张开检测\n        mouth_open = abs(landmarks[13].y - landmarks[14].y)\n        if mouth_open > 0.05:\n            return 'surprise'\n\n        # 微笑检测\n        left = landmarks[61].y\n        right = landmarks[291].y\n        center = landmarks[13].y\n        if left < center and right < center:\n            return 'smile'\n\n        return 'neutral'\n\n    def play_music(self, expression):\n        if expression != self.last_expression and expression in self.sounds:\n            self.sounds[expression].play()\n            self.last_expression = expression\n```\n\n**核心知识点**\n- 表情识别：通过关键点相对位置判断表情\n- 常用关键点：13(上唇)、14(下唇)、61(左嘴角)、291(右嘴角)\n- pygame音频：mixer.init()初始化，Sound()加载，play()播放\n\n`#执行层` `#测评项`\n[UID: PYAI-23-05-001]\n\n---\n\n### 2-3-6 表情控制进阶\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-6 |\n| **课程名称** | 表情控制进阶 |\n| **认知负荷** | 高 |\n| **核心技能** | 多表情识别、表情强度计算、pygame界面 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们升级表情识别系统，不仅识别表情类型，还要计算**表情强度**！\"\n>\n> \"**表情强度计算**：\n> ```python\n> # 微笑强度 = 嘴角上扬程度\n> def smile_intensity(landmarks):\n>     left_corner = landmarks[61]\n>     right_corner = landmarks[291]\n>     mouth_center = landmarks[13]\n>\n>     # 计算嘴角相对于嘴唇中点的上扬距离\n>     left_lift = mouth_center.y - left_corner.y\n>     right_lift = mouth_center.y - right_corner.y\n>\n>     # 取平均值，归一化到0-100\n>     intensity = (left_lift + right_lift) / 2 * 1000\n>     return max(0, min(100, intensity))\n> ```\n>\n> **眉毛检测**（皱眉/惊讶）：\n> ```python\n> # 眉毛关键点\n> left_eyebrow = landmarks[70]   # 左眉中点\n> right_eyebrow = landmarks[300] # 右眉中点\n> left_eye = landmarks[159]      # 左眼上方\n>\n> # 眉毛距离眼睛越近 = 皱眉\n> eyebrow_distance = left_eyebrow.y - left_eye.y\n> if eyebrow_distance < 0.02:\n>     print('皱眉')\n> elif eyebrow_distance > 0.05:\n>     print('惊讶（眉毛上扬）')\n> ```\"\n\n**步骤2：pygame界面设计（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"用pygame创建一个表情仪表盘：\n> ```python\n> import pygame\n>\n> def draw_emotion_meter(screen, emotion, intensity):\n>     # 绘制表情图标\n>     emoji_map = {'smile': ':)', 'sad': ':(', 'surprise': ':O'}\n>     font = pygame.font.Font(None, 72)\n>     text = font.render(emoji_map.get(emotion, ':|'), True, (255, 255, 255))\n>     screen.blit(text, (100, 100))\n>\n>     # 绘制强度条\n>     pygame.draw.rect(screen, (100, 100, 100), (50, 200, 200, 30))\n>     pygame.draw.rect(screen, (0, 255, 0), (50, 200, intensity * 2, 30))\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 强度计算不准 | 校准系数 | 根据实际测试调整归一化系数 |\n| 想加更多表情 | 组合特征 | 眉毛+嘴巴+眼睛组合判断 |\n| pygame窗口卡顿 | 降低帧率 | 设置pygame.time.Clock().tick(30) |\n\n---\n\n**核心知识点**\n- 表情强度：量化表情程度，不只是有/无\n- 眉毛检测：眉毛位置判断皱眉/惊讶\n- pygame界面：创建实时反馈的可视化界面\n\n`#执行层` `#测评项`\n[UID: PYAI-23-06-001]\n\n---\n\n### 2-3-7 手势识别\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-7 |\n| **课程名称** | 手势识别 |\n| **认知负荷** | 高 |\n| **核心技能** | MediaPipe Hands、21个关键点 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天学习用AI识别手势！MediaPipe Hands可以检测手部21个关键点。\"\n>\n> \"**关键点索引**：\n> - 0: 手腕\n> - 4: 大拇指指尖\n> - 8: 食指指尖\n> - 12: 中指指尖\n> - 16: 无名指指尖\n> - 20: 小拇指指尖\n>\n> **判断手指伸直**：如果指尖的Y坐标 < 指根的Y坐标，说明手指伸直\n> ```python\n> # 判断食指是否伸直\n> if landmark[8].y < landmark[6].y:\n>     print('食指伸直')\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 关键点搞混 | 画手型图 | 在纸上标注每个关键点位置 |\n| 想识别数字 | 组合判断 | 数字2=食指+中指伸直 |\n| 检测两只手 | 修改参数 | max_num_hands=2 |\n\n---\n\n**核心知识点**\n- MediaPipe Hands：手部21个关键点\n- 几何逻辑：判断每根手指的伸直/弯曲状态\n- 关键点索引：0是手腕，8是食指指尖\n\n`#执行层` `#测评项`\n[UID: PYAI-23-07-001]\n\n---\n\n### 2-3-8 手势控制应用\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-8 |\n| **课程名称** | 手势控制应用 |\n| **认知负荷** | 高 |\n| **核心技能** | 手势映射、pygame交互控制 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"上节课我们学会了识别手势，今天把手势变成**控制指令**！\"\n>\n> \"**手势映射设计**：\n> ```python\n> def gesture_to_command(fingers_up):\n>     '''\n>     fingers_up: [拇指, 食指, 中指, 无名指, 小指]\n>     返回: 控制指令\n>     '''\n>     if fingers_up == [0, 1, 0, 0, 0]:  # 只有食指\n>         return 'UP'\n>     elif fingers_up == [0, 1, 1, 0, 0]:  # 食指+中指\n>         return 'DOWN'\n>     elif fingers_up == [1, 1, 1, 1, 1]:  # 全部张开\n>         return 'STOP'\n>     elif fingers_up == [0, 0, 0, 0, 0]:  # 握拳\n>         return 'GO'\n>     return None\n> ```\n>\n> **pygame控制小球**：\n> ```python\n> import pygame\n>\n> ball_x, ball_y = 400, 300\n> speed = 5\n>\n> def move_ball(command):\n>     global ball_x, ball_y\n>     if command == 'UP':\n>         ball_y -= speed\n>     elif command == 'DOWN':\n>         ball_y += speed\n>     elif command == 'LEFT':\n>         ball_x -= speed\n>     elif command == 'RIGHT':\n>         ball_x += speed\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建一个手势控制游戏：\n> - 用手势控制小球移动\n> - 收集屏幕上的金币\n> - 避开障碍物\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 手势识别不稳定 | 添加确认机制 | 连续3帧相同手势才执行 |\n| 想用左右手 | 区分左右 | 检测handedness属性 |\n| 控制太灵敏 | 添加冷却时间 | 每个指令间隔0.5秒 |\n\n---\n\n**核心代码模式**\n```python\n# 手势控制游戏框架\nimport cv2\nimport mediapipe as mp\nimport pygame\n\nclass GestureController:\n    def __init__(self):\n        self.hands = mp.solutions.hands.Hands()\n        self.finger_tips = [4, 8, 12, 16, 20]  # 指尖索引\n        self.finger_pips = [3, 6, 10, 14, 18]  # 指根索引\n\n    def get_fingers_up(self, landmarks):\n        fingers = []\n        # 拇指特殊处理（比较x坐标）\n        if landmarks[4].x < landmarks[3].x:\n            fingers.append(1)\n        else:\n            fingers.append(0)\n        # 其他四指（比较y坐标）\n        for tip, pip in zip(self.finger_tips[1:], self.finger_pips[1:]):\n            if landmarks[tip].y < landmarks[pip].y:\n                fingers.append(1)\n            else:\n                fingers.append(0)\n        return fingers\n```\n\n**核心知识点**\n- 手势映射：将手指状态组合映射为控制指令\n- 指尖检测：比较指尖和指根的y坐标判断伸直\n- pygame交互：实时响应手势控制游戏元素\n\n`#执行层` `#测评项`\n[UID: PYAI-23-08-001]\n\n---\n\n### 2-3-9 手势绘画板\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-9 |\n| **课程名称** | 手势绘画板 |\n| **认知负荷** | 高 |\n| **核心技能** | 指尖追踪、轨迹绘制、颜色切换 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们做一个**空中绘画板**！用食指在空中画画，电脑会记录轨迹。\"\n>\n> \"**指尖追踪**：\n> ```python\n> # 获取食指指尖坐标\n> index_tip = landmarks[8]\n>\n> # 转换为像素坐标\n> h, w = frame.shape[:2]\n> x = int(index_tip.x * w)\n> y = int(index_tip.y * h)\n> ```\n>\n> **轨迹绘制**：\n> ```python\n> # 用列表存储轨迹点\n> draw_points = []\n>\n> # 只有食指伸出时才绘制\n> if fingers_up == [0, 1, 0, 0, 0]:\n>     draw_points.append((x, y))\n>\n> # 绘制轨迹\n> for i in range(1, len(draw_points)):\n>     cv2.line(canvas, draw_points[i-1], draw_points[i], color, 5)\n> ```\n>\n> **手势切换颜色**：\n> ```python\n> colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]\n> color_index = 0\n>\n> # 竖起两根手指切换颜色\n> if fingers_up == [0, 1, 1, 0, 0]:\n>     color_index = (color_index + 1) % len(colors)\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建你的手势绘画板：\n> - 食指绘画\n> - 两指切换颜色\n> - 握拳清除画布\n> - 五指张开保存图片\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 线条断断续续 | 降低检测阈值 | 或增加点之间的连线距离阈值 |\n| 想画不同粗细 | 添加手势 | 用手指数量控制线条粗细 |\n| 想加橡皮擦 | 特殊手势 | 用拇指+小指表示橡皮擦模式 |\n\n---\n\n**核心代码模式**\n```python\n# 手势绘画板完整框架\nimport cv2\nimport numpy as np\nimport mediapipe as mp\n\nclass GestureDrawingBoard:\n    def __init__(self, width=1280, height=720):\n        self.canvas = np.zeros((height, width, 3), dtype=np.uint8)\n        self.colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n        self.color_index = 0\n        self.prev_point = None\n        self.drawing = False\n\n    def process(self, frame, landmarks, fingers_up):\n        h, w = frame.shape[:2]\n        x = int(landmarks[8].x * w)\n        y = int(landmarks[8].y * h)\n\n        # 食指绘画\n        if fingers_up == [0, 1, 0, 0, 0]:\n            if self.prev_point:\n                cv2.line(self.canvas, self.prev_point, (x, y),\n                        self.colors[self.color_index], 5)\n            self.prev_point = (x, y)\n        else:\n            self.prev_point = None\n\n        # 两指切换颜色\n        if fingers_up == [0, 1, 1, 0, 0]:\n            self.color_index = (self.color_index + 1) % len(self.colors)\n\n        # 握拳清除\n        if fingers_up == [0, 0, 0, 0, 0]:\n            self.canvas = np.zeros_like(self.canvas)\n\n        return self.canvas\n```\n\n**核心知识点**\n- 指尖追踪：获取landmark[8]的坐标并转换为像素\n- 轨迹绘制：存储点序列，用cv2.line连接相邻点\n- 画布叠加：用numpy创建透明画布，与视频帧叠加\n\n`#执行层` `#测评项`\n[UID: PYAI-23-09-001]\n\n---\n\n### 2-3-10~11 机械手游戏\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-10/11 |\n| **课程名称** | 机械手游戏（猜拳） |\n| **认知负荷** | 中-高/高 |\n| **核心技能** | random库、概率算法 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天做一个猜拳机器人！先学习基础版：\n>\n> **识别玩家手势**：\n> - 石头：所有手指弯曲\n> - 剪刀：食指+中指伸直\n> - 布：所有手指伸直\n>\n> **电脑出拳**：\n> ```python\n> import random\n> computer = random.choice(['rock', 'scissors', 'paper'])\n> ```\n>\n> **进阶版：无敌猜拳王**\n> 记录玩家出拳习惯，用权重随机针对性出拳：\n> ```python\n> # 如果玩家喜欢出石头，电脑就多出布\n> weights = [0.2, 0.3, 0.5]  # 石头、剪刀、布的权重\n> computer = random.choices(['rock', 'scissors', 'paper'], weights)[0]\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解权重 | 用概率类比 | \"就像抽奖，奖品越多越容易抽到\" |\n| 想让AI更强 | 增加策略 | 记录最近3次出拳，预测下一次 |\n| 想做GUI | 加入pygame | 用pygame做游戏界面 |\n\n---\n\n**核心知识点**\n- random.choice()：随机选择\n- random.choices()：权重随机\n- 概率算法：记录玩家出拳习惯，针对性出拳\n\n`#执行层` `#测评项`\n[UID: PYAI-23-10-001]\n\n---"
    },
    {
      "title": "教学禁忌清单",
      "content": "| 序号 | 禁忌 | 原因 | 正确做法 |\n|------|------|------|----------|\n| 1 | 关键点索引乱填 | 获取错误坐标 | 结合图示明确关键点索引 |\n| 2 | 像素坐标使用浮点数 | 报错 | 必须使用int()转换为整数 |\n| 3 | 忽视BGR/RGB转换 | 颜色错误 | OpenCV是BGR，MediaPipe是RGB，需转换 |\n| 4 | 忘记释放摄像头 | 下次无法使用 | 程序结束前cap.release() |\n\n`#执行层` `#测评项`\n[UID: PYAI-TABOO-23]\n\n---"
    },
    {
      "title": "教学注意事项",
      "content": "| 类别 | 注意事项 |\n|------|----------|\n| **关键点索引** | FaceMesh有468个点，Hand有21个点，需结合图示明确索引 |\n| **坐标转换** | 计算结果可能是浮点数，必须用int()转换 |\n| **通道顺序** | OpenCV默认BGR，MediaPipe使用RGB，传递前需转换 |\n| **性能优化** | 摄像头帧率可能较低，注意优化代码 |\n\n---"
    },
    {
      "title": "底层教育学原理",
      "content": "| 原理 | 说明 | 在本单元的应用 |\n|------|------|----------------|\n| **AIoT闭环** | 感知-判断-执行 | 眼睛检测→阈值判断→灯控制 |\n| **预训练模型应用** | 使用现成AI模型 | MediaPipe的FaceMesh、Hands |\n| **概率与策略** | 数据驱动决策 | 猜拳机器人的概率算法 |\n| **人机交互** | 自然交互方式 | 眨眼、手势控制 |\n\n`#执行层` `#测评项`\n[UID: PYAI-THEORY-23]\n\n---\n\n**质量评估**：10/10（原子化萃取版，11节课完整萃取）\n**已补充**：认知负荷标签、IFC标签、变体示例、详细教师话术、核心代码模式\n**课程覆盖**：2-3-1至2-3-11全部11节课\n\n---\n\n**最后更新**：2026-02-09"
    }
  ],
  "full_content": "# PythonAI萃取：L2-3 交互式AI与仿生控制\n\n> **来源**：NotebookLM Python AI Lesson Plan (96个来源)\n> **萃取日期**：2026-02-02\n> **萃取深度**：5-5多维度（含认知负荷标签、IFC标签、变体示例）\n> **更新日期**：2026-02-04\n\n---\n\n## 单元概览\n\n| 项目 | 内容 |\n|------|------|\n| **单元编号** | PYAI 2-3 |\n| **单元名称** | 交互式AI与仿生控制 |\n| **适用年龄** | 四年级及以上（10-12岁） |\n| **课时数** | 11节 × 90分钟 |\n| **核心目标** | 结合MediaPipe视觉模型与硬件控制，实现AIoT闭环 |\n| **核心库** | MediaPipe (FaceMesh, Hands), pygame, OpenCV |\n\n**底层逻辑**\n实现\"视觉识别-逻辑判断-硬件执行\"的AIoT闭环，培养AI应用能力。\n\n**单元教学策略**\n- 面部检测（01-02）：FaceMesh、眨眼检测\n- 表情识别（05）：关键点特征提取\n- 手势控制（07-11）：Hands模型、猜拳游戏\n\n`#执行层` `#测评项`\n[UID: PYAI-23-001]\n[关联: PYAI-14-001 PythonAI智能硬件（前置基础）]\n[关联: PYAI-24-001 PythonAI计算机视觉（并行学习）]\n\n---\n\n## 课程列表\n\n| 课次 | 课程名称 | 核心知识点 | 项目内容 | 认知负荷 |\n|------|----------|------------|----------|----------|\n| 2-3-1 | 眼控开关1 | MediaPipe FaceMesh、enumerate()、abs()/int() | 眨眼检测基础 | 高 |\n| 2-3-2 | 眼控开关2 | 阈值判定、状态机逻辑、cv2.putText | 智能灯控 | 高 |\n| 2-3-3 | 眼控开关3 | 状态机设计、防抖动处理、GPIO控制 | 眨眼控制进阶 | 高 |\n| 2-3-4 | 眼控开关4 | 多功能眼控、UI反馈、项目整合 | 眼控智能家居 | 高 |\n| 2-3-5 | 表情控制 | 关键点特征、pygame音频播放 | 表情音乐播放器 | 高 |\n| 2-3-6 | 表情控制进阶 | 多表情识别、表情强度计算、pygame界面 | 表情仪表盘 | 高 |\n| 2-3-7 | 手势识别 | MediaPipe Hands、21个关键点 | 手势判定 | 高 |\n| 2-3-8 | 手势控制应用 | 手势映射、pygame交互控制 | 手势控制游戏 | 高 |\n| 2-3-9 | 手势绘画板 | 指尖追踪、轨迹绘制、颜色切换 | 空中绘画 | 高 |\n| 2-3-10 | 机械手游戏(1) | random库、石头剪刀布判定 | 猜拳机器人 | 中-高 |\n| 2-3-11 | 机械手游戏(2) | random.choices()权重随机、概率算法 | 无敌猜拳王 | 高 |\n\n---\n\n## 通用教学流程（90分钟）\n\n| 环节 | 时间 | 内容 | 认知负荷 | IFC标签 |\n|------|------|------|----------|---------|\n| 课堂问候 | 2分钟 | 自我介绍、学习目标 | `#低负荷-热身` | `#IFC-预防` |\n| 课程回顾 | 5分钟 | 复习上节课代码知识 | `#低负荷-热身` | `#IFC-预防` |\n| 知识讲解 | 20分钟 | 新AI模型/概念讲解 | `#中负荷-操练` | `#IFC-即时` |\n| 代码实践 | 35分钟 | 编写代码、调试 | `#高负荷-产出` | `#IFC-即时` |\n| 调节休息 | 3分钟 | 站起来活动、眼保健操 | `#调节-放松` | - |\n| 项目拓展 | 15分钟 | 综合应用/挑战 | `#高负荷-产出` | `#IFC-即时` |\n| 成果展示 | 10分钟 | 分享代码、讲解思路 | `#低负荷-热身` | `#IFC-复盘` |\n\n`#执行层` `#测评项`\n[UID: PYAI-23-FLOW-001]\n\n---\n\n## 详细课程萃取\n\n### 2-3-1~2 眼控开关（典型案例）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-1/2 |\n| **课程名称** | 眼控开关 |\n| **认知负荷** | 高 |\n| **核心技能** | FaceMesh、眨眼检测、阈值判定 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们来做一个神奇的功能——**眨眼开灯**！用眼睛控制开关，是不是很酷？\"\n>\n> \"原理是用**FaceMesh**检测面部468个关键点，计算上下眼睑的距离：\n> ```python\n> import mediapipe as mp\n>\n> face_mesh = mp.solutions.face_mesh.FaceMesh()\n> results = face_mesh.process(frame)\n>\n> # 获取眼睛关键点\n> upper_lid = results.multi_face_landmarks[0].landmark[159]\n> lower_lid = results.multi_face_landmarks[0].landmark[145]\n>\n> # 计算眼睛开合度\n> eye_distance = abs(upper_lid.y - lower_lid.y)\n> ```\n>\n> 当距离小于阈值（比如0.01），判定为闭眼！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 阈值不准 | 实测调整 | 打印eye_distance观察正常值 |\n| 想检测嘴巴 | 换关键点 | 用嘴唇的关键点检测张嘴 |\n| 检测不稳定 | 添加滤波 | 连续N帧闭眼才判定为闭眼 |\n\n---\n\n**核心知识点**\n- FaceMesh：面部网格模型，468个关键点\n- 眨眼检测：计算上下眼睑关键点的垂直距离\n- 阈值判定：距离差 < 阈值 → 判定为闭眼\n\n`#执行层` `#测评项`\n[UID: PYAI-23-01-001]\n\n---\n\n### 2-3-3 眼控开关3（进阶）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-3 |\n| **课程名称** | 眼控开关3（进阶） |\n| **认知负荷** | 高 |\n| **核心技能** | 状态机设计、防抖动处理、GPIO控制 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"前两节课我们实现了眨眼检测，但有个问题——眨眼太快会误触发！今天学习**状态机**和**防抖动**。\"\n>\n> \"**状态机设计**：用变量记录当前状态\n> ```python\n> # 状态定义\n> STATE_OPEN = 0   # 眼睛睁开\n> STATE_CLOSED = 1 # 眼睛闭合\n> current_state = STATE_OPEN\n> blink_count = 0\n>\n> # 状态转换逻辑\n> if eye_distance < threshold:\n>     if current_state == STATE_OPEN:\n>         current_state = STATE_CLOSED\n>         blink_count += 1\n> else:\n>     current_state = STATE_OPEN\n> ```\n>\n> **防抖动处理**：连续N帧才确认状态变化\n> ```python\n> close_frames = 0\n> DEBOUNCE_FRAMES = 3  # 连续3帧才确认\n>\n> if eye_distance < threshold:\n>     close_frames += 1\n>     if close_frames >= DEBOUNCE_FRAMES:\n>         # 确认闭眼\n>         trigger_action()\n> else:\n>     close_frames = 0\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在我们把眨眼检测和硬件控制结合起来！\n> 眨眼一次开灯，再眨眼一次关灯。\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 状态切换太快 | 增加防抖帧数 | 把DEBOUNCE_FRAMES改为5 |\n| 想用双眨眼触发 | 添加计数器 | 1秒内眨眼2次才触发 |\n| 没有硬件 | 用屏幕模拟 | 用pygame画一个灯泡 |\n\n---\n\n**核心代码模式**\n```python\n# 完整的眨眼控制状态机\nclass BlinkController:\n    def __init__(self, threshold=0.01, debounce=3):\n        self.threshold = threshold\n        self.debounce = debounce\n        self.close_frames = 0\n        self.light_on = False\n\n    def update(self, eye_distance):\n        if eye_distance < self.threshold:\n            self.close_frames += 1\n            if self.close_frames == self.debounce:\n                self.light_on = not self.light_on\n                return self.light_on\n        else:\n            self.close_frames = 0\n        return None  # 无状态变化\n```\n\n**核心知识点**\n- 状态机：用变量记录和管理程序状态\n- 防抖动：连续N帧确认，避免误触发\n- 边沿检测：只在状态变化时触发动作\n\n`#执行层` `#测评项`\n[UID: PYAI-23-03-001]\n\n---\n\n### 2-3-4 眼控开关4（综合应用）\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-4 |\n| **课程名称** | 眼控开关4（综合应用） |\n| **认知负荷** | 高 |\n| **核心技能** | 多功能眼控、UI反馈、项目整合 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们把前三节课的内容整合成一个完整的**眼控系统**！\n>\n> **功能设计**：\n> - 眨眼1次：开/关灯\n> - 眨眼2次：切换模式\n> - 长闭眼（2秒）：紧急停止\n>\n> **UI反馈设计**：\n> ```python\n> import cv2\n>\n> def draw_ui(frame, light_on, mode):\n>     # 绘制状态指示\n>     color = (0, 255, 0) if light_on else (0, 0, 255)\n>     cv2.circle(frame, (50, 50), 20, color, -1)\n>\n>     # 显示当前模式\n>     cv2.putText(frame, f'Mode: {mode}', (100, 50),\n>                 cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n>     return frame\n> ```\"\n\n**步骤2：项目整合（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"现在把所有功能整合到一个程序中，创建你的眼控智能家居系统！\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 功能太多记不住 | 简化功能 | 先只做开关灯，再逐步添加 |\n| 想加声音提示 | 用pygame | pygame.mixer播放提示音 |\n| 想控制多个设备 | 扩展状态 | 用列表管理多个设备状态 |\n\n---\n\n**核心知识点**\n- 项目整合：将多个功能模块组合成完整系统\n- UI反馈：用视觉元素显示系统状态\n- 多功能触发：不同操作触发不同功能\n\n`#执行层` `#测评项`\n[UID: PYAI-23-04-001]\n\n---\n\n### 2-3-5 表情控制\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-5 |\n| **课程名称** | 表情控制 |\n| **认知负荷** | 高 |\n| **核心技能** | 关键点特征提取、pygame音频播放 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们用FaceMesh识别表情！不同表情会播放不同音乐。\"\n>\n> \"**表情识别原理**：通过关键点的相对位置判断表情\n>\n> **嘴巴张开检测**：\n> ```python\n> # 上嘴唇和下嘴唇的关键点\n> upper_lip = landmarks[13]  # 上嘴唇中点\n> lower_lip = landmarks[14]  # 下嘴唇中点\n>\n> mouth_open = abs(upper_lip.y - lower_lip.y)\n> if mouth_open > 0.05:\n>     print('嘴巴张开了！')\n> ```\n>\n> **微笑检测**：\n> ```python\n> # 嘴角的关键点\n> left_corner = landmarks[61]   # 左嘴角\n> right_corner = landmarks[291] # 右嘴角\n> mouth_center = landmarks[13]  # 嘴唇中点\n>\n> # 嘴角上扬 = 微笑\n> if left_corner.y < mouth_center.y and right_corner.y < mouth_center.y:\n>     print('检测到微笑！')\n> ```\"\n\n**步骤2：pygame音频播放（15分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"学习用pygame播放音乐：\n> ```python\n> import pygame\n>\n> pygame.mixer.init()\n>\n> # 加载音乐\n> happy_music = pygame.mixer.Sound('happy.wav')\n> sad_music = pygame.mixer.Sound('sad.wav')\n>\n> # 播放音乐\n> if is_smiling:\n>     happy_music.play()\n> elif is_mouth_open:\n>     sad_music.play()\n> ```\"\n\n**步骤3：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建一个表情音乐播放器：\n> - 微笑 → 播放欢快音乐\n> - 张嘴 → 播放惊讶音效\n> - 皱眉 → 播放悲伤音乐\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 关键点索引记不住 | 提供索引表 | 打印常用关键点索引对照表 |\n| 音乐文件找不到 | 检查路径 | 使用绝对路径或放在同一目录 |\n| 表情识别不准 | 调整阈值 | 打印数值，根据实际情况调整 |\n| 想识别更多表情 | 组合特征 | 眉毛+嘴巴组合判断复杂表情 |\n\n---\n\n**核心代码模式**\n```python\n# 表情音乐播放器完整代码框架\nimport cv2\nimport mediapipe as mp\nimport pygame\n\npygame.mixer.init()\n\nclass ExpressionMusicPlayer:\n    def __init__(self):\n        self.face_mesh = mp.solutions.face_mesh.FaceMesh()\n        self.sounds = {\n            'smile': pygame.mixer.Sound('happy.wav'),\n            'surprise': pygame.mixer.Sound('surprise.wav')\n        }\n        self.last_expression = None\n\n    def detect_expression(self, landmarks):\n        # 嘴巴张开检测\n        mouth_open = abs(landmarks[13].y - landmarks[14].y)\n        if mouth_open > 0.05:\n            return 'surprise'\n\n        # 微笑检测\n        left = landmarks[61].y\n        right = landmarks[291].y\n        center = landmarks[13].y\n        if left < center and right < center:\n            return 'smile'\n\n        return 'neutral'\n\n    def play_music(self, expression):\n        if expression != self.last_expression and expression in self.sounds:\n            self.sounds[expression].play()\n            self.last_expression = expression\n```\n\n**核心知识点**\n- 表情识别：通过关键点相对位置判断表情\n- 常用关键点：13(上唇)、14(下唇)、61(左嘴角)、291(右嘴角)\n- pygame音频：mixer.init()初始化，Sound()加载，play()播放\n\n`#执行层` `#测评项`\n[UID: PYAI-23-05-001]\n\n---\n\n### 2-3-6 表情控制进阶\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-6 |\n| **课程名称** | 表情控制进阶 |\n| **认知负荷** | 高 |\n| **核心技能** | 多表情识别、表情强度计算、pygame界面 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们升级表情识别系统，不仅识别表情类型，还要计算**表情强度**！\"\n>\n> \"**表情强度计算**：\n> ```python\n> # 微笑强度 = 嘴角上扬程度\n> def smile_intensity(landmarks):\n>     left_corner = landmarks[61]\n>     right_corner = landmarks[291]\n>     mouth_center = landmarks[13]\n>\n>     # 计算嘴角相对于嘴唇中点的上扬距离\n>     left_lift = mouth_center.y - left_corner.y\n>     right_lift = mouth_center.y - right_corner.y\n>\n>     # 取平均值，归一化到0-100\n>     intensity = (left_lift + right_lift) / 2 * 1000\n>     return max(0, min(100, intensity))\n> ```\n>\n> **眉毛检测**（皱眉/惊讶）：\n> ```python\n> # 眉毛关键点\n> left_eyebrow = landmarks[70]   # 左眉中点\n> right_eyebrow = landmarks[300] # 右眉中点\n> left_eye = landmarks[159]      # 左眼上方\n>\n> # 眉毛距离眼睛越近 = 皱眉\n> eyebrow_distance = left_eyebrow.y - left_eye.y\n> if eyebrow_distance < 0.02:\n>     print('皱眉')\n> elif eyebrow_distance > 0.05:\n>     print('惊讶（眉毛上扬）')\n> ```\"\n\n**步骤2：pygame界面设计（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"用pygame创建一个表情仪表盘：\n> ```python\n> import pygame\n>\n> def draw_emotion_meter(screen, emotion, intensity):\n>     # 绘制表情图标\n>     emoji_map = {'smile': ':)', 'sad': ':(', 'surprise': ':O'}\n>     font = pygame.font.Font(None, 72)\n>     text = font.render(emoji_map.get(emotion, ':|'), True, (255, 255, 255))\n>     screen.blit(text, (100, 100))\n>\n>     # 绘制强度条\n>     pygame.draw.rect(screen, (100, 100, 100), (50, 200, 200, 30))\n>     pygame.draw.rect(screen, (0, 255, 0), (50, 200, intensity * 2, 30))\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 强度计算不准 | 校准系数 | 根据实际测试调整归一化系数 |\n| 想加更多表情 | 组合特征 | 眉毛+嘴巴+眼睛组合判断 |\n| pygame窗口卡顿 | 降低帧率 | 设置pygame.time.Clock().tick(30) |\n\n---\n\n**核心知识点**\n- 表情强度：量化表情程度，不只是有/无\n- 眉毛检测：眉毛位置判断皱眉/惊讶\n- pygame界面：创建实时反馈的可视化界面\n\n`#执行层` `#测评项`\n[UID: PYAI-23-06-001]\n\n---\n\n### 2-3-7 手势识别\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-7 |\n| **课程名称** | 手势识别 |\n| **认知负荷** | 高 |\n| **核心技能** | MediaPipe Hands、21个关键点 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天学习用AI识别手势！MediaPipe Hands可以检测手部21个关键点。\"\n>\n> \"**关键点索引**：\n> - 0: 手腕\n> - 4: 大拇指指尖\n> - 8: 食指指尖\n> - 12: 中指指尖\n> - 16: 无名指指尖\n> - 20: 小拇指指尖\n>\n> **判断手指伸直**：如果指尖的Y坐标 < 指根的Y坐标，说明手指伸直\n> ```python\n> # 判断食指是否伸直\n> if landmark[8].y < landmark[6].y:\n>     print('食指伸直')\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 关键点搞混 | 画手型图 | 在纸上标注每个关键点位置 |\n| 想识别数字 | 组合判断 | 数字2=食指+中指伸直 |\n| 检测两只手 | 修改参数 | max_num_hands=2 |\n\n---\n\n**核心知识点**\n- MediaPipe Hands：手部21个关键点\n- 几何逻辑：判断每根手指的伸直/弯曲状态\n- 关键点索引：0是手腕，8是食指指尖\n\n`#执行层` `#测评项`\n[UID: PYAI-23-07-001]\n\n---\n\n### 2-3-8 手势控制应用\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-8 |\n| **课程名称** | 手势控制应用 |\n| **认知负荷** | 高 |\n| **核心技能** | 手势映射、pygame交互控制 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"上节课我们学会了识别手势，今天把手势变成**控制指令**！\"\n>\n> \"**手势映射设计**：\n> ```python\n> def gesture_to_command(fingers_up):\n>     '''\n>     fingers_up: [拇指, 食指, 中指, 无名指, 小指]\n>     返回: 控制指令\n>     '''\n>     if fingers_up == [0, 1, 0, 0, 0]:  # 只有食指\n>         return 'UP'\n>     elif fingers_up == [0, 1, 1, 0, 0]:  # 食指+中指\n>         return 'DOWN'\n>     elif fingers_up == [1, 1, 1, 1, 1]:  # 全部张开\n>         return 'STOP'\n>     elif fingers_up == [0, 0, 0, 0, 0]:  # 握拳\n>         return 'GO'\n>     return None\n> ```\n>\n> **pygame控制小球**：\n> ```python\n> import pygame\n>\n> ball_x, ball_y = 400, 300\n> speed = 5\n>\n> def move_ball(command):\n>     global ball_x, ball_y\n>     if command == 'UP':\n>         ball_y -= speed\n>     elif command == 'DOWN':\n>         ball_y += speed\n>     elif command == 'LEFT':\n>         ball_x -= speed\n>     elif command == 'RIGHT':\n>         ball_x += speed\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建一个手势控制游戏：\n> - 用手势控制小球移动\n> - 收集屏幕上的金币\n> - 避开障碍物\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 手势识别不稳定 | 添加确认机制 | 连续3帧相同手势才执行 |\n| 想用左右手 | 区分左右 | 检测handedness属性 |\n| 控制太灵敏 | 添加冷却时间 | 每个指令间隔0.5秒 |\n\n---\n\n**核心代码模式**\n```python\n# 手势控制游戏框架\nimport cv2\nimport mediapipe as mp\nimport pygame\n\nclass GestureController:\n    def __init__(self):\n        self.hands = mp.solutions.hands.Hands()\n        self.finger_tips = [4, 8, 12, 16, 20]  # 指尖索引\n        self.finger_pips = [3, 6, 10, 14, 18]  # 指根索引\n\n    def get_fingers_up(self, landmarks):\n        fingers = []\n        # 拇指特殊处理（比较x坐标）\n        if landmarks[4].x < landmarks[3].x:\n            fingers.append(1)\n        else:\n            fingers.append(0)\n        # 其他四指（比较y坐标）\n        for tip, pip in zip(self.finger_tips[1:], self.finger_pips[1:]):\n            if landmarks[tip].y < landmarks[pip].y:\n                fingers.append(1)\n            else:\n                fingers.append(0)\n        return fingers\n```\n\n**核心知识点**\n- 手势映射：将手指状态组合映射为控制指令\n- 指尖检测：比较指尖和指根的y坐标判断伸直\n- pygame交互：实时响应手势控制游戏元素\n\n`#执行层` `#测评项`\n[UID: PYAI-23-08-001]\n\n---\n\n### 2-3-9 手势绘画板\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-9 |\n| **课程名称** | 手势绘画板 |\n| **认知负荷** | 高 |\n| **核心技能** | 指尖追踪、轨迹绘制、颜色切换 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天我们做一个**空中绘画板**！用食指在空中画画，电脑会记录轨迹。\"\n>\n> \"**指尖追踪**：\n> ```python\n> # 获取食指指尖坐标\n> index_tip = landmarks[8]\n>\n> # 转换为像素坐标\n> h, w = frame.shape[:2]\n> x = int(index_tip.x * w)\n> y = int(index_tip.y * h)\n> ```\n>\n> **轨迹绘制**：\n> ```python\n> # 用列表存储轨迹点\n> draw_points = []\n>\n> # 只有食指伸出时才绘制\n> if fingers_up == [0, 1, 0, 0, 0]:\n>     draw_points.append((x, y))\n>\n> # 绘制轨迹\n> for i in range(1, len(draw_points)):\n>     cv2.line(canvas, draw_points[i-1], draw_points[i], color, 5)\n> ```\n>\n> **手势切换颜色**：\n> ```python\n> colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]\n> color_index = 0\n>\n> # 竖起两根手指切换颜色\n> if fingers_up == [0, 1, 1, 0, 0]:\n>     color_index = (color_index + 1) % len(colors)\n> ```\"\n\n**步骤2：代码实践（35分钟）** `#高负荷-产出` `#IFC-即时`\n\n**教师话术**\n> \"创建你的手势绘画板：\n> - 食指绘画\n> - 两指切换颜色\n> - 握拳清除画布\n> - 五指张开保存图片\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 线条断断续续 | 降低检测阈值 | 或增加点之间的连线距离阈值 |\n| 想画不同粗细 | 添加手势 | 用手指数量控制线条粗细 |\n| 想加橡皮擦 | 特殊手势 | 用拇指+小指表示橡皮擦模式 |\n\n---\n\n**核心代码模式**\n```python\n# 手势绘画板完整框架\nimport cv2\nimport numpy as np\nimport mediapipe as mp\n\nclass GestureDrawingBoard:\n    def __init__(self, width=1280, height=720):\n        self.canvas = np.zeros((height, width, 3), dtype=np.uint8)\n        self.colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n        self.color_index = 0\n        self.prev_point = None\n        self.drawing = False\n\n    def process(self, frame, landmarks, fingers_up):\n        h, w = frame.shape[:2]\n        x = int(landmarks[8].x * w)\n        y = int(landmarks[8].y * h)\n\n        # 食指绘画\n        if fingers_up == [0, 1, 0, 0, 0]:\n            if self.prev_point:\n                cv2.line(self.canvas, self.prev_point, (x, y),\n                        self.colors[self.color_index], 5)\n            self.prev_point = (x, y)\n        else:\n            self.prev_point = None\n\n        # 两指切换颜色\n        if fingers_up == [0, 1, 1, 0, 0]:\n            self.color_index = (self.color_index + 1) % len(self.colors)\n\n        # 握拳清除\n        if fingers_up == [0, 0, 0, 0, 0]:\n            self.canvas = np.zeros_like(self.canvas)\n\n        return self.canvas\n```\n\n**核心知识点**\n- 指尖追踪：获取landmark[8]的坐标并转换为像素\n- 轨迹绘制：存储点序列，用cv2.line连接相邻点\n- 画布叠加：用numpy创建透明画布，与视频帧叠加\n\n`#执行层` `#测评项`\n[UID: PYAI-23-09-001]\n\n---\n\n### 2-3-10~11 机械手游戏\n\n#### 课程基本信息\n\n| 项目 | 内容 |\n|------|------|\n| **课程编号** | 2-3-10/11 |\n| **课程名称** | 机械手游戏（猜拳） |\n| **认知负荷** | 中-高/高 |\n| **核心技能** | random库、概率算法 |\n\n#### 详细教学流程\n\n**步骤1：知识讲解（20分钟）** `#中负荷-操练` `#IFC-即时`\n\n**教师话术**\n> \"今天做一个猜拳机器人！先学习基础版：\n>\n> **识别玩家手势**：\n> - 石头：所有手指弯曲\n> - 剪刀：食指+中指伸直\n> - 布：所有手指伸直\n>\n> **电脑出拳**：\n> ```python\n> import random\n> computer = random.choice(['rock', 'scissors', 'paper'])\n> ```\n>\n> **进阶版：无敌猜拳王**\n> 记录玩家出拳习惯，用权重随机针对性出拳：\n> ```python\n> # 如果玩家喜欢出石头，电脑就多出布\n> weights = [0.2, 0.3, 0.5]  # 石头、剪刀、布的权重\n> computer = random.choices(['rock', 'scissors', 'paper'], weights)[0]\n> ```\"\n\n**变体示例**\n\n| 学生情况 | 调整方案 | 说明 |\n|----------|----------|------|\n| 不理解权重 | 用概率类比 | \"就像抽奖，奖品越多越容易抽到\" |\n| 想让AI更强 | 增加策略 | 记录最近3次出拳，预测下一次 |\n| 想做GUI | 加入pygame | 用pygame做游戏界面 |\n\n---\n\n**核心知识点**\n- random.choice()：随机选择\n- random.choices()：权重随机\n- 概率算法：记录玩家出拳习惯，针对性出拳\n\n`#执行层` `#测评项`\n[UID: PYAI-23-10-001]\n\n---\n\n## 教学禁忌清单\n\n| 序号 | 禁忌 | 原因 | 正确做法 |\n|------|------|------|----------|\n| 1 | 关键点索引乱填 | 获取错误坐标 | 结合图示明确关键点索引 |\n| 2 | 像素坐标使用浮点数 | 报错 | 必须使用int()转换为整数 |\n| 3 | 忽视BGR/RGB转换 | 颜色错误 | OpenCV是BGR，MediaPipe是RGB，需转换 |\n| 4 | 忘记释放摄像头 | 下次无法使用 | 程序结束前cap.release() |\n\n`#执行层` `#测评项`\n[UID: PYAI-TABOO-23]\n\n---\n\n## 教学注意事项\n\n| 类别 | 注意事项 |\n|------|----------|\n| **关键点索引** | FaceMesh有468个点，Hand有21个点，需结合图示明确索引 |\n| **坐标转换** | 计算结果可能是浮点数，必须用int()转换 |\n| **通道顺序** | OpenCV默认BGR，MediaPipe使用RGB，传递前需转换 |\n| **性能优化** | 摄像头帧率可能较低，注意优化代码 |\n\n---\n\n## 底层教育学原理\n\n| 原理 | 说明 | 在本单元的应用 |\n|------|------|----------------|\n| **AIoT闭环** | 感知-判断-执行 | 眼睛检测→阈值判断→灯控制 |\n| **预训练模型应用** | 使用现成AI模型 | MediaPipe的FaceMesh、Hands |\n| **概率与策略** | 数据驱动决策 | 猜拳机器人的概率算法 |\n| **人机交互** | 自然交互方式 | 眨眼、手势控制 |\n\n`#执行层` `#测评项`\n[UID: PYAI-THEORY-23]\n\n---\n\n**质量评估**：10/10（原子化萃取版，11节课完整萃取）\n**已补充**：认知负荷标签、IFC标签、变体示例、详细教师话术、核心代码模式\n**课程覆盖**：2-3-1至2-3-11全部11节课\n\n---\n\n**最后更新**：2026-02-09\n"
}