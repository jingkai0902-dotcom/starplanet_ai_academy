#!/usr/bin/env python3
"""
æ–¯å¦æ˜ŸçƒçŸ¥è¯†åº“é’‰é’‰æœºå™¨äºº - RAGæ¨¡å¼
ä½¿ç”¨Claude APIåŸºäºçŸ¥è¯†åº“å†…å®¹ç”Ÿæˆå›ç­”

åŠŸèƒ½ï¼š
- è¯¾ç¨‹å’¨è¯¢ï¼ˆSTEM/CODE/PythonAI/C++ä¿¡å¥¥ï¼‰
- é”€å”®è¯æœ¯æŒ‡å¯¼
- æ•™å­¦é—®é¢˜è§£ç­”
- å®¶é•¿æ²Ÿé€šå»ºè®®
"""

import hashlib
import hmac
import base64
import json
import re
import logging
import threading
from pathlib import Path
from flask import Flask, request, jsonify
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# ============== é…ç½®åŒºåŸŸ ==============
CONFIG = {
    "app_key": "",           # é’‰é’‰åº”ç”¨AppKey
    "app_secret": "",        # é’‰é’‰åº”ç”¨AppSecret
    "agent_id": "",          # é’‰é’‰æœºå™¨äººAgentID
    "kb_path": "",           # çŸ¥è¯†åº“JSONæ–‡ä»¶ç›®å½•
    "llm_provider": "zhipu",
    "llm_api_key": "",       # å¤§æ¨¡å‹APIå¯†é’¥
    "llm_base_url": "https://open.bigmodel.cn/api/paas/v4",
    "llm_model": "glm-4.7",
    "claude_api_key": "",    # å…¼å®¹æ—§é…ç½®
    "claude_base_url": "",   # å…¼å®¹æ—§é…ç½®
}

# ============== ç”¨æˆ·èº«ä»½è¯†åˆ« ==============

def get_user_info(data: dict) -> dict:
    """ä»é’‰é’‰å›è°ƒæ•°æ®ä¸­æå–ç”¨æˆ·ä¿¡æ¯"""
    return {
        "staff_id": data.get("senderStaffId", ""),
        "sender_nick": data.get("senderNick", ""),
        "sender_id": data.get("senderId", ""),
    }


# ============== çŸ¥è¯†åº“åŠ è½½ä¸æœç´¢ ==============

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).parent / "config.json"
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            loaded = json.load(f)
            CONFIG.update(loaded)

    if not CONFIG["kb_path"]:
        CONFIG["kb_path"] = str(Path(__file__).parent / "knowledge_base")


def build_content_from_sections(sections: list) -> str:
    """å°†sectionsåˆå¹¶ä¸ºå¯æ£€ç´¢çš„æ­£æ–‡å†…å®¹"""
    parts = []
    for sec in sections or []:
        if not isinstance(sec, dict):
            continue
        title = (sec.get("title") or "").strip()
        content = (sec.get("content") or "").strip()
        if not title and not content:
            continue
        if title:
            parts.append(f"## {title}\n{content}".strip())
        else:
            parts.append(content)
    return "\n\n".join([p for p in parts if p])


def load_knowledge_base():
    """åŠ è½½çŸ¥è¯†åº“æ‰€æœ‰æ–‡æ¡£"""
    kb_dir = Path(CONFIG["kb_path"])
    documents = []

    if not kb_dir.exists():
        logger.error(f"çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {kb_dir}")
        return []

    for json_file in kb_dir.glob("*.json"):
        if json_file.name == "_index.json":
            continue

        try:
            with open(json_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            # entriesåˆ—è¡¨æ ¼å¼
            if "entries" in data:
                for entry in data["entries"]:
                    documents.append({
                        "title": entry.get("title", ""),
                        "source": json_file.name,
                        "content": entry.get("content", {}).get("raw", ""),
                        "sections": []
                    })
            # mdè½¬æ¢çš„JSONæ ¼å¼ï¼ˆfull_contentæˆ–sectionsï¼‰
            elif "title" in data:
                sections = data.get("sections", [])
                content = data.get("full_content") or build_content_from_sections(sections) or data.get("content", "")
                if content:
                    documents.append({
                        "title": data.get("title", ""),
                        "source": data.get("source", json_file.name),
                        "content": content,
                        "sections": sections
                    })
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½ {json_file.name}: {e}")

    logger.info(f"å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
    return documents


def extract_query_terms(query: str) -> list[str]:
    """æå–æŸ¥è¯¢å…³é”®è¯ï¼ˆæ”¯æŒä¸­æ–‡ã€æ•°å­—ã€è¯¾ç¨‹ç¼–å·ï¼‰"""
    query_lower = query.lower()
    terms = set()

    # è‹±æ–‡/æ•°å­—è¿ç»­ç‰‡æ®µ
    for token in re.findall(r"[a-z0-9]+", query_lower):
        terms.add(token)

    # è¯¾ç¨‹ç¼–å·ï¼ˆå¦‚ 1-1-2ï¼‰
    for token in re.findall(r"\d+(?:-\d+)+", query_lower):
        terms.add(token)
        parts = token.split("-")
        if len(parts) >= 2:
            terms.add("-".join(parts[:2]))

    # ä¸­æ–‡è¿ç»­ç‰‡æ®µä¸äºŒå­—åˆ‡åˆ†
    for token in re.findall(r"[\u4e00-\u9fff]+", query_lower):
        terms.add(token)
        if len(token) >= 2:
            for i in range(len(token) - 1):
                terms.add(token[i:i + 2])

    if not terms:
        terms.add(query_lower.strip())

    return list(terms)


def extract_snippet(content: str, terms: list[str], before: int = 400, after: int = 1200) -> str | None:
    """ä»å†…å®¹ä¸­æˆªå–åŒ…å«å…³é”®è¯çš„ç‰‡æ®µ"""
    if not content or not terms:
        return None
    content_lower = content.lower()
    best = None  # (count, pos)
    best_pos = None
    for term in terms:
        if not term:
            continue
        if len(term) < 2:
            continue
        pos = content_lower.find(term)
        if pos == -1:
            continue
        count = content_lower.count(term)
        candidate = (count, pos)
        if best is None or candidate < best:
            best = candidate
            best_pos = pos
    if best_pos is None:
        return None
    start = max(best_pos - before, 0)
    end = min(best_pos + after, len(content))
    return content[start:end]


def search_documents(query: str, documents: list, max_results: int = 5) -> list:
    """æœç´¢ç›¸å…³æ–‡æ¡£"""
    query_lower = query.lower()
    query_terms = extract_query_terms(query)
    results = []

    for doc in documents:
        score = 0
        title_raw = doc.get("title", "")
        content_raw = doc.get("content", "")
        sections = doc.get("sections", [])
        section_text = []
        if sections:
            for sec in sections:
                if isinstance(sec, dict):
                    section_text.append(sec.get("title", ""))
                    section_text.append(sec.get("content", ""))
        content_raw_combined = content_raw
        if section_text:
            content_raw_combined = content_raw + "\n" + "\n".join(section_text)

        title = title_raw.lower()
        content = content_raw_combined.lower()

        for term in query_terms:
            if term in title:
                score += 10
            if term in content:
                score += 3 + content.count(term)

        # æ–¯å¦æ˜Ÿçƒä¸“ç”¨å…³é”®è¯åŠ æƒ
        keywords = {
            # STEMç›¸å…³
            "stem": ["stem", "å¹¼å„¿", "ç§‘åˆ›", "æœºæ¢°", "å»ºç­‘", "ç‰©ç†"],
            "å°ç­": ["å°ç­", "3-4å²", "è®¤è¯†æˆ‘è‡ªå·±", "åŠ¨ç‰©", "æ¤ç‰©"],
            "ä¸­ç­": ["ä¸­ç­", "4-5å²", "æœºæ¢°", "å»ºç­‘", "æ™ºèƒ½"],
            "å¤§ç­": ["å¤§ç­", "5-6å²", "å¤æ‚æœºæ¢°", "èƒ½æº", "ç©ºé—´", "æ™ºèƒ½ç¡¬ä»¶"],
            # CODEç›¸å…³
            "code": ["code", "scratch", "ç¼–ç¨‹", "å°‘å„¿ç¼–ç¨‹", "æ¸¸æˆå¼€å‘"],
            "code1": ["code1", "æœºæ¢°ç»“æ„", "æ™ºèƒ½ç¡¬ä»¶", "ç¼–ç¨‹å¯è’™"],
            "code2": ["code2", "æ™ºèƒ½åº”ç”¨", "æ™ºèƒ½äº¤äº’", "ç®—æ³•é€»è¾‘"],
            "code3": ["code3", "æ™ºèƒ½ç³»ç»Ÿ", "æ¸¸æˆå¼€å‘", "é«˜çº§å·¥ç¨‹"],
            # Pythonç›¸å…³
            "python": ["python", "pythonai", "äººå·¥æ™ºèƒ½", "ai"],
            "l1": ["l1", "å‡½æ•°", "ç®—æ³•", "æ•°æ®ç»“æ„"],
            "l2": ["l2", "æ•°æ®ç§‘å­¦", "è®¡ç®—æœºè§†è§‰", "cv", "ä»¿ç”Ÿ"],
            # C++ä¿¡å¥¥
            "ä¿¡å¥¥": ["ä¿¡å¥¥", "c++", "noi", "csp", "ç«èµ›"],
            # é”€å”®ç›¸å…³
            "é”€å”®": ["é”€å”®", "è¯æœ¯", "å’¨è¯¢", "å¼‚è®®", "ä¿ƒå•"],
            "å®¶é•¿": ["å®¶é•¿", "æ²Ÿé€š", "ç»­è´¹", "è½¬ä»‹ç»"],
        }

        for key, terms in keywords.items():
            if any(t in query_lower for t in terms):
                if any(t in title or t in content for t in terms):
                    score += 5

        if score > 0:
            doc["_score"] = score
            snippet = extract_snippet(content_raw_combined, query_terms)
            if snippet:
                doc["_snippet"] = snippet
            results.append(doc)

    results.sort(key=lambda x: x.get("_score", 0), reverse=True)
    return results[:max_results]


# ============== Claude RAG ==============

def build_context(documents: list, max_chars: int = 8000) -> str:
    """æ„å»ºä¸Šä¸‹æ–‡ï¼Œæ§åˆ¶é•¿åº¦"""
    context_parts = []
    total_chars = 0

    for doc in documents:
        title = doc.get("title", "æœªçŸ¥")
        content = doc.get("_snippet") or doc.get("content", "")

        if total_chars + len(content) > max_chars:
            remaining = max_chars - total_chars
            if remaining > 500:
                content = content[:remaining] + "\n...(å†…å®¹æˆªæ–­)"
            else:
                break

        context_parts.append(f"### {title}\n\n{content}")
        total_chars += len(content)

    return "\n\n---\n\n".join(context_parts)


def get_llm_config():
    """è·å–å¤§æ¨¡å‹é…ç½®ï¼ˆä¼˜å…ˆè¯»å–llm_*, å…¼å®¹claude_*ï¼‰"""
    api_key = CONFIG.get("llm_api_key") or CONFIG.get("claude_api_key") or ""
    base_url = CONFIG.get("llm_base_url") or CONFIG.get("claude_base_url") or "https://open.bigmodel.cn/api/paas/v4"
    model = CONFIG.get("llm_model") or "glm-4.7"
    return api_key, base_url, model


def ask_llm(question: str, context: str) -> str:
    """è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”ï¼ˆæ™ºè°±OpenAIå…¼å®¹æ¥å£ï¼‰"""
    api_key, base_url, model = get_llm_config()
    if not api_key:
        return "é”™è¯¯ï¼šæœªé…ç½®å¤§æ¨¡å‹APIå¯†é’¥"

    system_prompt = """ä½ æ˜¯æ–¯å¦æ˜Ÿçƒçš„çŸ¥è¯†åº“åŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”è€å¸ˆå’Œé”€å”®é¡¾é—®å…³äºè¯¾ç¨‹ã€æ•™å­¦ã€é”€å”®çš„é—®é¢˜ã€‚

æ–¯å¦æ˜Ÿçƒç®€ä»‹ï¼š
- ä¸“æ³¨äºSTEMç§‘åˆ›å’Œç¼–ç¨‹æ•™è‚²
- è¯¾ç¨‹ä½“ç³»ï¼šSTEMå¹¼å„¿ç§‘åˆ›ï¼ˆ3-6å²ï¼‰â†’ CODEå°‘å„¿ç¼–ç¨‹ï¼ˆ6-12å²ï¼‰â†’ PythonAIï¼ˆ10å²+ï¼‰â†’ C++ä¿¡å¥¥
- æ•™å­¦ç†å¿µï¼šé¡¹ç›®åˆ¶å­¦ä¹ (PBL)ã€å…«å¤§èƒ½åŠ›åŸ¹å…»ã€åšä¸­å­¦

é‡è¦è§„åˆ™ï¼š
1. åªèƒ½åŸºäºæä¾›çš„çŸ¥è¯†åº“å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä»»ä½•ä¿¡æ¯
2. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œæ˜ç¡®è¯´"è¿™ä¸ªé—®é¢˜æˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³èµ„æ–™ï¼Œå»ºè®®å’¨è¯¢æ•™å­¦ä¸»ç®¡"
3. å›ç­”è¦ç®€æ´å®ç”¨ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆ
4. æ¶‰åŠå…·ä½“è¯¾ç¨‹ã€å¹´é¾„ã€çº§åˆ«æ—¶ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§çŸ¥è¯†åº“å†…å®¹
5. ç”¨å£è¯­åŒ–çš„æ–¹å¼å›ç­”ï¼ŒåƒåŒäº‹ä¹‹é—´çš„å¯¹è¯

è¯¾ç¨‹ä½“ç³»è¦ç‚¹ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
- STEMï¼šå°ç­(3-4å²)â†’ä¸­ç­(4-5å²)â†’å¤§ç­(5-6å²)ï¼Œæ¯é˜¶æ®µ4ä¸ªä¸»é¢˜
- CODEï¼šCODE1(6-8å²)â†’CODE2(8-10å²)â†’CODE3(10-12å²)ï¼Œæœºæ¢°+ç¼–ç¨‹ç»“åˆ
- PythonAIï¼šL1(10-12å²)â†’L2(12å²+)ï¼Œäººå·¥æ™ºèƒ½æ–¹å‘
- C++ä¿¡å¥¥ï¼šé¢å‘ç«èµ›çš„ä¸“ä¸šè¯¾ç¨‹"""

    user_message = f"""è¯·åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ã€‚

ã€çŸ¥è¯†åº“å†…å®¹ã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

è¯·ç›´æ¥å›ç­”ï¼Œä¸è¦è¯´"æ ¹æ®çŸ¥è¯†åº“"ä¹‹ç±»çš„å¼€åœºç™½ã€‚"""

    url = base_url.rstrip("/") + "/chat/completions"
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
        "temperature": 0.2,
        "max_tokens": 1200,
        "thinking": {"type": "disabled"},
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=30)
        if resp.status_code != 200:
            logger.error(f"LLMé”™è¯¯: {resp.status_code} {resp.text[:300]}")
            return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        data = resp.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        if not content:
            logger.error(f"LLMè¿”å›ç©ºå†…å®¹: {data}")
            return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        return content.strip()
    except Exception as e:
        logger.error(f"LLMè°ƒç”¨å¼‚å¸¸: {e}")
        return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºé”™äº†ã€‚"


def process_question(question: str, documents: list) -> str:
    """å¤„ç†ç”¨æˆ·é—®é¢˜ï¼šæœç´¢+ç”Ÿæˆ"""
    relevant_docs = search_documents(question, documents, max_results=5)

    if not relevant_docs:
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•æ¢ä¸ªå…³é”®è¯ï¼Œæˆ–å’¨è¯¢æ•™å­¦ä¸»ç®¡ã€‚"

    context = build_context(relevant_docs)
    answer = ask_llm(question, context)

    return answer


# ============== é’‰é’‰æ¥å£ ==============

def verify_signature(timestamp: str, sign: str) -> bool:
    """éªŒè¯é’‰é’‰è¯·æ±‚ç­¾å"""
    if not CONFIG["app_secret"]:
        return True

    string_to_sign = f"{timestamp}\n{CONFIG['app_secret']}"
    hmac_code = hmac.new(
        CONFIG["app_secret"].encode("utf-8"),
        string_to_sign.encode("utf-8"),
        digestmod=hashlib.sha256
    ).digest()
    calculated_sign = base64.b64encode(hmac_code).decode("utf-8")

    return sign == calculated_sign


def send_message(webhook_url: str, content: str):
    """é€šè¿‡Webhookå‘é€æ¶ˆæ¯"""
    headers = {"Content-Type": "application/json"}
    data = {
        "msgtype": "text",
        "text": {"content": content}
    }

    try:
        resp = requests.post(webhook_url, json=data, headers=headers, timeout=30)
        logger.info(f"æ¶ˆæ¯å‘é€ç»“æœ: {resp.status_code}")
    except Exception as e:
        logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")


def handle_text_message(content: str, session_webhook: str):
    """åå°å¤„ç†æ¶ˆæ¯å¹¶å‘é€å›å¤ï¼Œé¿å…å›è°ƒè¶…æ—¶"""
    try:
        reply = None

        # å¸®åŠ©å‘½ä»¤
        if content in ["å¸®åŠ©", "help", "?"]:
            reply = """ğŸ¤– æ–¯å¦æ˜ŸçƒçŸ¥è¯†åº“åŠ©æ‰‹

ç›´æ¥è¾“å…¥é—®é¢˜å³å¯ï¼Œä¾‹å¦‚ï¼š
â€¢ STEMå°ç­å­¦ä»€ä¹ˆå†…å®¹ï¼Ÿ
â€¢ CODE1å’ŒCODE2æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
â€¢ å®¶é•¿é—®Pythonæœ‰ä»€ä¹ˆç”¨æ€ä¹ˆå›ç­”ï¼Ÿ
â€¢ å­©å­å¤šå¤§å¯ä»¥å­¦ç¼–ç¨‹ï¼Ÿ
â€¢ å®¶é•¿è¯´ä»·æ ¼è´µæ€ä¹ˆå¤„ç†ï¼Ÿ

ğŸ“š æ”¯æŒçš„çŸ¥è¯†é¢†åŸŸï¼š
â€¢ è¯¾ç¨‹ä½“ç³»ï¼ˆSTEM/CODE/PythonAI/C++ä¿¡å¥¥ï¼‰
â€¢ é”€å”®è¯æœ¯ä¸å¼‚è®®å¤„ç†
â€¢ æ•™å­¦æ–¹æ³•ä¸è¯¾å ‚ç®¡ç†
â€¢ å®¶é•¿æ²Ÿé€šæŠ€å·§

ğŸ’¡ æç¤ºï¼šæ‚¨ä¹Ÿå¯ä»¥ç§èŠæˆ‘ï¼Œè·å¾—æ›´ä¸“æ³¨çš„æœåŠ¡"""

        # å¿«æ·å‘½ä»¤
        elif content.startswith("/"):
            cmd = content[1:].lower()
            if cmd == "stem":
                reply = """ğŸ“˜ STEMå¹¼å„¿ç§‘åˆ›è¯¾ç¨‹ï¼ˆ3-6å²ï¼‰

ã€å°ç­ 3-4å²ã€‘
é˜¶æ®µ1ï¼šè®¤è¯†æˆ‘è‡ªå·± - èº«ä½“éƒ¨ä½ã€æ„Ÿå®˜æ¢ç´¢
é˜¶æ®µ2ï¼šåŠ¨ç‰©ç‹å›½ - åŠ¨ç‰©ç‰¹å¾ã€ä»¿ç”Ÿè®¾è®¡
é˜¶æ®µ3ï¼šæ¤ç‰©å¥¥ç§˜ - æ¤ç‰©ç”Ÿé•¿ã€è§‚å¯Ÿè®°å½•
é˜¶æ®µ4ï¼šæ•°ç†ç‰©ç† - åŸºç¡€ç‰©ç†ã€æ•°å­¦å¯è’™

ã€ä¸­ç­ 4-5å²ã€‘
é˜¶æ®µ1ï¼šæœºæ¢°ä¸å·¥å…· - æ æ†ã€æ»‘è½®ã€é½¿è½®
é˜¶æ®µ2ï¼šå»ºç­‘ä¸ç»“æ„ - æ¡¥æ¢ã€å¡”æ¥¼ã€ç¨³å®šæ€§
é˜¶æ®µ3ï¼šæ™ºèƒ½æœºæ¢° - ç”µåŠ¨é©¬è¾¾ã€ä¼ åŠ¨ç³»ç»Ÿ
é˜¶æ®µ4ï¼šç‰©ç†ç§‘å­¦ - å£°å…‰ç”µçƒ­æ¢ç´¢

ã€å¤§ç­ 5-6å²ã€‘
é˜¶æ®µ1ï¼šå¤æ‚æœºæ¢° - ç»¼åˆæœºæ¢°ç³»ç»Ÿ
é˜¶æ®µ2ï¼šåœ°çƒä¸ç©ºé—´ - å¤©æ–‡ã€åœ°ç†
é˜¶æ®µ3ï¼šèƒ½æºç§‘å­¦ - æ–°èƒ½æºã€ç”µè·¯
é˜¶æ®µ4ï¼šæ™ºèƒ½ç¡¬ä»¶ - ç¼–ç¨‹åˆä½“éªŒ

ğŸ’¡ æƒ³äº†è§£æ›´å¤šï¼Ÿå¯ä»¥é—®æˆ‘å…·ä½“è¯¾æ—¶å†…å®¹"""

            elif cmd == "code":
                reply = """ğŸ’» CODEå°‘å„¿ç¼–ç¨‹è¯¾ç¨‹ï¼ˆ6-12å²ï¼‰

ã€CODE1 6-8å²ã€‘ä¹é«˜+Scratchå¯è’™
â€¢ æ¨¡å—1ï¼šæœºæ¢°ç»“æ„åŸºç¡€
â€¢ æ¨¡å—2ï¼šæ™ºèƒ½ç¡¬ä»¶ä¸ä»¿ç”Ÿ
â€¢ æ¨¡å—3ï¼šScratchç¼–ç¨‹å¯è’™
â€¢ æ¨¡å—4ï¼šç¼–ç¨‹é€»è¾‘è¿›é˜¶

ã€CODE2 8-10å²ã€‘è¿›é˜¶ç¼–ç¨‹
â€¢ æ¨¡å—1ï¼šæ™ºèƒ½ç”Ÿæ´»åº”ç”¨
â€¢ æ¨¡å—2ï¼šæ™ºèƒ½äº¤äº’ç³»ç»Ÿ
â€¢ æ¨¡å—3ï¼šç®—æ³•ä¸æ•°å­¦é€»è¾‘

ã€CODE3 10-12å²ã€‘é«˜çº§å·¥ç¨‹
â€¢ æ¨¡å—1ï¼šæ™ºèƒ½ç³»ç»Ÿè®¾è®¡
â€¢ æ¨¡å—2ï¼šæ¸¸æˆå¼€å‘PBL
â€¢ æ¨¡å—3ï¼šé«˜çº§æœºæ¢°å·¥ç¨‹

ç‰¹è‰²ï¼šæœºæ¢°æ­å»º+å›¾å½¢åŒ–ç¼–ç¨‹+é€»è¾‘æ€ç»´

ğŸ’¡ æƒ³äº†è§£å‡ç­è§„åˆ™ï¼Ÿé—®æˆ‘ CODEæ€ä¹ˆå‡ç­"""

            elif cmd == "python":
                reply = """ğŸ PythonAIè¯¾ç¨‹ï¼ˆ10å²+ï¼‰

ã€L1é˜¶æ®µ 10-12å²ã€‘PythonåŸºç¡€+AIå¯è’™
â€¢ æ¨¡å—0ï¼šåŸºç¡€è¯­æ³•ä¸é€»è¾‘å¯è’™
â€¢ æ¨¡å—1ï¼šå‡½æ•°å°è£…ä¸äº¤äº’æœºåˆ¶
â€¢ æ¨¡å—2ï¼šç®—æ³•é€»è¾‘ä¸æ•°å€¼è¿ç®—
â€¢ æ¨¡å—3ï¼šæ•°æ®ç»“æ„ä¸å¤æ‚é€»è¾‘
â€¢ æ¨¡å—4ï¼šæ™ºèƒ½ç¡¬ä»¶ä¸AIåº”ç”¨

ã€L2é˜¶æ®µ 12å²+ã€‘AIè¿›é˜¶
â€¢ æ¨¡å—1ï¼šç®—æ³•ä¸æ•°æ®ç§‘å­¦
â€¢ æ¨¡å—2ï¼šAIå¯¹è¯ä¸æ™ºèƒ½ä½“
â€¢ æ¨¡å—3ï¼šäº¤äº’å¼AIä¸ä»¿ç”Ÿæ§åˆ¶
â€¢ æ¨¡å—4ï¼šè®¡ç®—æœºè§†è§‰(CV)

ç‰¹è‰²ï¼šå®æˆ˜é¡¹ç›®é©±åŠ¨ã€AIåº”ç”¨å¼€å‘

ğŸ’¡ æƒ³äº†è§£å…¥å­¦è¯„ä¼°ï¼Ÿé—®æˆ‘ Pythonæ€ä¹ˆæµ‹è¯„"""

            elif cmd in ["ä»·æ ¼", "ä¿ƒå•"]:
                reply = """ğŸ’° å¸¸è§ä»·æ ¼å¼‚è®®å¤„ç†

ã€å¤ªè´µäº†ã€‘
âœ… è®¤åŒ â†’ æ‹†åˆ†ä»·å€¼ â†’ å¯¹æ¯”æŠ•å…¥
"ç†è§£æ‚¨çš„é¡¾è™‘ã€‚å’±ä»¬æ‹†å¼€ç®—ä¸€ä¸‹ï¼ŒXXè¯¾æ—¶å¹³å‡æ¯æ¬¡è¯¾XXå…ƒï¼Œä¸€å‘¨Xæ¬¡ï¼Œå­¦ä¸‹æ¥å­©å­èƒ½è·å¾—..."

ã€å†è€ƒè™‘ã€‘
âœ… è®¤åŒ â†’ æ¢è¯¢çœŸå®åŸå›  â†’ è§£å†³é¡¾è™‘
"å®Œå…¨ç†è§£ï¼Œé‚£æ‚¨ä¸»è¦æ˜¯æƒ³è€ƒè™‘å“ªæ–¹é¢å‘¢ï¼Ÿæ˜¯æ—¶é—´å®‰æ’è¿˜æ˜¯...ï¼Ÿ"

ã€åˆ«å®¶ä¾¿å®œã€‘
âœ… ä¸å¦å®š â†’ å·®å¼‚åŒ– â†’ ä»·å€¼é”šå®š
"æ˜¯çš„ï¼Œå¸‚é¢ä¸Šä»·æ ¼åŒºé—´å¾ˆå¤§ã€‚å’±ä»¬çš„ç‰¹ç‚¹æ˜¯...æ‚¨å¯ä»¥å¯¹æ¯”ä¸€ä¸‹è¯¾ç¨‹å†…å®¹å’Œå¸ˆèµ„..."

ğŸ’¡ æƒ³è¦æ›´å¤šè¯æœ¯ï¼Ÿé—®æˆ‘ å¼‚è®®å¤„ç†"""

        # æ™®é€šé—®ç­”
        if reply is None:
            reply = process_question(content, KB_DOCUMENTS)

        if session_webhook:
            send_message(session_webhook, reply)
    except Exception as e:
        logger.exception(f"åå°å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")


# ============== è·¯ç”± ==============

KB_DOCUMENTS = []


@app.before_request
def ensure_kb_loaded():
    """ç¡®ä¿çŸ¥è¯†åº“å·²åŠ è½½"""
    global KB_DOCUMENTS
    if not KB_DOCUMENTS:
        load_config()
        KB_DOCUMENTS = load_knowledge_base()


@app.route("/", methods=["GET"])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "ok",
        "service": "æ–¯å¦æ˜ŸçƒçŸ¥è¯†åº“é’‰é’‰æœºå™¨äºº(RAG+Claude)",
        "documents": len(KB_DOCUMENTS)
    })


@app.route("/dingtalk/callback", methods=["POST"])
def dingtalk_callback():
    """é’‰é’‰æ¶ˆæ¯å›è°ƒ"""
    try:
        data = request.json
        logger.info(f"æ”¶åˆ°æ¶ˆæ¯: {json.dumps(data, ensure_ascii=False)[:300]}")

        # éªŒè¯ç­¾å
        timestamp = request.headers.get("timestamp", "")
        sign = request.headers.get("sign", "")
        if CONFIG["app_secret"] and not verify_signature(timestamp, sign):
            return jsonify({"errcode": 403, "errmsg": "ç­¾åéªŒè¯å¤±è´¥"})

        msg_type = data.get("msgtype", "")

        if msg_type == "text":
            content = data.get("text", {}).get("content", "").strip()
            session_webhook = data.get("sessionWebhook", "")

            if not content:
                return jsonify({"errcode": 0, "errmsg": "ok"})

            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = get_user_info(data)
            logger.info(f"ç”¨æˆ·: {user_info['sender_nick']}, StaffID: {user_info['staff_id']}")
            # åå°å¤„ç†ï¼Œé¿å…å›è°ƒè¶…æ—¶
            if session_webhook:
                threading.Thread(
                    target=handle_text_message,
                    args=(content, session_webhook),
                    daemon=True
                ).start()

        return jsonify({"errcode": 0, "errmsg": "ok"})

    except Exception as e:
        logger.exception(f"å¤„ç†å›è°ƒå¼‚å¸¸: {e}")
        return jsonify({"errcode": 500, "errmsg": str(e)})


# ============== å¯åŠ¨ ==============

if __name__ == "__main__":
    load_config()
    KB_DOCUMENTS = load_knowledge_base()

    print("=" * 50)
    print("æ–¯å¦æ˜ŸçƒçŸ¥è¯†åº“é’‰é’‰æœºå™¨äºº (RAG + Claude)")
    print(f"å·²åŠ è½½ {len(KB_DOCUMENTS)} ä¸ªæ–‡æ¡£")
    print("=" * 50)

    app.run(host="0.0.0.0", port=8081, debug=True)
