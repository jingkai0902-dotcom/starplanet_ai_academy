# [PYAI-2-4-12] 动物伙伴

> **模块**：L2-M4 计算机视觉
> **认知负荷**：高
> **核心技能**：Pose模型、GIF处理、位置跟随
> **UID**：PYAI-24-12-001

---

## 课程基本信息

| 项目 | 内容 |
|------|------|
| **课程编号** | PYAI-2-4-12 |
| **课程名称** | 动物伙伴 - 肩膀上的宠物 |
| **认知负荷** | 高 |
| **核心技能** | Pose模型、GIF处理、位置跟随 |
| **项目内容** | 肩膀上的宠物 |

---

## 详细教学流程

### 步骤1：知识讲解（20分钟）

`#中负荷-操练` `#IFC-即时`

**教师话术**
> "今天我们来做一个超酷的AR效果——**肩膀上的虚拟宠物**！
>
> 需要解决三个问题：
> 1. **找到肩膀位置**：用MediaPipe Pose模型检测身体关键点
> 2. **加载动画宠物**：处理GIF动图
> 3. **让宠物跟随移动**：实时更新位置
>
> ```python
> import mediapipe as mp
>
> # 初始化Pose模型
> mp_pose = mp.solutions.pose
> pose = mp_pose.Pose()
>
> # 处理图像获取关键点
> results = pose.process(frame_rgb)
>
> # 获取左肩位置（索引11）和右肩位置（索引12）
> if results.pose_landmarks:
>     left_shoulder = results.pose_landmarks.landmark[11]
>     right_shoulder = results.pose_landmarks.landmark[12]
>     # 坐标是0-1的比例，需要乘以图像尺寸
>     x = int(left_shoulder.x * width)
>     y = int(left_shoulder.y * height)
> ```"

**变体示例**

| 学生情况 | 调整方案 | 说明 |
|----------|----------|------|
| 想放在头顶 | 改用头部关键点 | 索引0是鼻子，可以往上偏移 |
| 宠物太大/太小 | 根据肩宽缩放 | 用两肩距离计算合适的宠物大小 |
| 想用静态图片 | 简化为PNG | 不需要GIF处理，直接叠加 |

---

### 步骤2：代码实践（35分钟）

`#高负荷-产出` `#IFC-即时`

**教师话术**
> "现在我们来处理GIF动图。Python可以用PIL库读取GIF的每一帧：
>
> ```python
> from PIL import Image
> import numpy as np
>
> # 加载GIF
> gif = Image.open('pet.gif')
> frames = []
>
> # 提取所有帧
> try:
>     while True:
>         # 转换为RGBA（带透明通道）
>         frame = gif.convert('RGBA')
>         frames.append(np.array(frame))
>         gif.seek(gif.tell() + 1)  # 下一帧
> except EOFError:
>     pass  # 读完了
>
> # 循环播放
> frame_index = 0
> pet_frame = frames[frame_index % len(frames)]
> frame_index += 1
> ```"

---

### 步骤3：叠加宠物（15分钟）

`#高负荷-产出` `#IFC-即时`

**教师话术**
> "最后把宠物叠加到肩膀位置。注意处理透明通道：
>
> ```python
> def overlay_image(background, overlay, x, y):
>     '''将带透明通道的图片叠加到背景上'''
>     h, w = overlay.shape[:2]
>
>     # 确保不超出边界
>     if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:
>         return background
>
>     # 分离Alpha通道
>     alpha = overlay[:, :, 3] / 255.0
>     alpha = np.stack([alpha, alpha, alpha], axis=-1)
>
>     # 混合
>     roi = background[y:y+h, x:x+w]
>     blended = (1 - alpha) * roi + alpha * overlay[:, :, :3]
>     background[y:y+h, x:x+w] = blended.astype(np.uint8)
>
>     return background
> ```"

---

## 核心代码模式

```python
# Pose关键点检测标准模板
pose = mp.solutions.pose.Pose()
results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
if results.pose_landmarks:
    landmark = results.pose_landmarks.landmark[index]
    x, y = int(landmark.x * w), int(landmark.y * h)
```

---

## 禁忌提醒

- 坐标超出图像边界——叠加前必须检查
- GIF帧索引越界——用取余`%`循环
- 忘记转换颜色空间——Pose需要RGB输入
- Alpha通道处理错误——导致宠物有白边

---

## 核心知识点

- Pose模型：33个身体关键点检测
- 关键点索引：11左肩、12右肩、0鼻子
- GIF处理：PIL读取、逐帧提取
- Alpha混合：透明图片叠加公式

**底层逻辑**
- **人体姿态估计**：AI模型识别身体关键点
- **动画循环**：帧索引取余实现无限循环
- **透明度混合**：`(1-alpha)*背景 + alpha*前景`

`#执行层` `#测评项`
[UID: PYAI-24-12-001]
[关联: PYAI-24-10-001 虚拟墨镜（前置课程）]

---

[上一课](PYAI-2-4-10_虚拟墨镜.md) | [模块概览](_模块概览.md) | [返回索引](../_索引.md)
